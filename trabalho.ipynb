{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# Install java\n",
        "!apt install openjdk-21-jdk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "mE1noAqF9PdU",
        "outputId": "1630778c-83b5-4e9e-ff2f-8cc77a3e8b16"
      },
      "id": "mE1noAqF9PdU",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java libatk-wrapper-java-jni libfontenc1\n",
            "  libice-dev libsm-dev libxkbfile1 libxt-dev libxtst6 libxxf86dga1 openjdk-21-jdk-headless\n",
            "  openjdk-21-jre openjdk-21-jre-headless x11-utils\n",
            "Suggested packages:\n",
            "  libice-doc libsm-doc libxt-doc openjdk-21-demo openjdk-21-source visualvm libnss-mdns\n",
            "  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei | fonts-wqy-zenhei fonts-indic\n",
            "  mesa-utils\n",
            "The following NEW packages will be installed:\n",
            "  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java libatk-wrapper-java-jni libfontenc1\n",
            "  libice-dev libsm-dev libxkbfile1 libxt-dev libxtst6 libxxf86dga1 openjdk-21-jdk\n",
            "  openjdk-21-jdk-headless openjdk-21-jre openjdk-21-jre-headless x11-utils\n",
            "0 upgraded, 16 newly installed, 0 to remove and 29 not upgraded.\n",
            "Need to get 135 MB of archives.\n",
            "After this operation, 315 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-core all 2.37-2build1 [1,041 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-extra all 2.37-2build1 [2,041 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbfile1 amd64 1:1.1.0-1build3 [71.8 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxtst6 amd64 2:1.2.3-1build4 [13.4 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxxf86dga1 amd64 2:1.1.5-0ubuntu3 [12.6 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-utils amd64 7.7+5build2 [206 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java all 0.38.0-5build1 [53.1 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java-jni amd64 0.38.0-5build1 [49.0 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libice-dev amd64 2:1.0.10-1build2 [51.4 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsm-dev amd64 2:1.2.3-1build2 [18.1 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxt-dev amd64 1:1.2.1-1 [396 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-21-jre-headless amd64 21.0.6+7-1~22.04.1 [46.8 MB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-21-jre amd64 21.0.6+7-1~22.04.1 [233 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-21-jdk-headless amd64 21.0.6+7-1~22.04.1 [82.6 MB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-21-jdk amd64 21.0.6+7-1~22.04.1 [1,649 kB]\n",
            "Fetched 135 MB in 2s (74.3 MB/s)\n",
            "Selecting previously unselected package fonts-dejavu-core.\n",
            "(Reading database ... 125044 files and directories currently installed.)\n",
            "Preparing to unpack .../00-fonts-dejavu-core_2.37-2build1_all.deb ...\n",
            "Unpacking fonts-dejavu-core (2.37-2build1) ...\n",
            "Selecting previously unselected package fonts-dejavu-extra.\n",
            "Preparing to unpack .../01-fonts-dejavu-extra_2.37-2build1_all.deb ...\n",
            "Unpacking fonts-dejavu-extra (2.37-2build1) ...\n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "Preparing to unpack .../02-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Selecting previously unselected package libxkbfile1:amd64.\n",
            "Preparing to unpack .../03-libxkbfile1_1%3a1.1.0-1build3_amd64.deb ...\n",
            "Unpacking libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "Preparing to unpack .../04-libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package libxxf86dga1:amd64.\n",
            "Preparing to unpack .../05-libxxf86dga1_2%3a1.1.5-0ubuntu3_amd64.deb ...\n",
            "Unpacking libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
            "Selecting previously unselected package x11-utils.\n",
            "Preparing to unpack .../06-x11-utils_7.7+5build2_amd64.deb ...\n",
            "Unpacking x11-utils (7.7+5build2) ...\n",
            "Selecting previously unselected package libatk-wrapper-java.\n",
            "Preparing to unpack .../07-libatk-wrapper-java_0.38.0-5build1_all.deb ...\n",
            "Unpacking libatk-wrapper-java (0.38.0-5build1) ...\n",
            "Selecting previously unselected package libatk-wrapper-java-jni:amd64.\n",
            "Preparing to unpack .../08-libatk-wrapper-java-jni_0.38.0-5build1_amd64.deb ...\n",
            "Unpacking libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n",
            "Selecting previously unselected package libice-dev:amd64.\n",
            "Preparing to unpack .../09-libice-dev_2%3a1.0.10-1build2_amd64.deb ...\n",
            "Unpacking libice-dev:amd64 (2:1.0.10-1build2) ...\n",
            "Selecting previously unselected package libsm-dev:amd64.\n",
            "Preparing to unpack .../10-libsm-dev_2%3a1.2.3-1build2_amd64.deb ...\n",
            "Unpacking libsm-dev:amd64 (2:1.2.3-1build2) ...\n",
            "Selecting previously unselected package libxt-dev:amd64.\n",
            "Preparing to unpack .../11-libxt-dev_1%3a1.2.1-1_amd64.deb ...\n",
            "Unpacking libxt-dev:amd64 (1:1.2.1-1) ...\n",
            "Selecting previously unselected package openjdk-21-jre-headless:amd64.\n",
            "Preparing to unpack .../12-openjdk-21-jre-headless_21.0.6+7-1~22.04.1_amd64.deb ...\n",
            "Unpacking openjdk-21-jre-headless:amd64 (21.0.6+7-1~22.04.1) ...\n",
            "Selecting previously unselected package openjdk-21-jre:amd64.\n",
            "Preparing to unpack .../13-openjdk-21-jre_21.0.6+7-1~22.04.1_amd64.deb ...\n",
            "Unpacking openjdk-21-jre:amd64 (21.0.6+7-1~22.04.1) ...\n",
            "Selecting previously unselected package openjdk-21-jdk-headless:amd64.\n",
            "Preparing to unpack .../14-openjdk-21-jdk-headless_21.0.6+7-1~22.04.1_amd64.deb ...\n",
            "Unpacking openjdk-21-jdk-headless:amd64 (21.0.6+7-1~22.04.1) ...\n",
            "Selecting previously unselected package openjdk-21-jdk:amd64.\n",
            "Preparing to unpack .../15-openjdk-21-jdk_21.0.6+7-1~22.04.1_amd64.deb ...\n",
            "Unpacking openjdk-21-jdk:amd64 (21.0.6+7-1~22.04.1) ...\n",
            "Setting up openjdk-21-jre-headless:amd64 (21.0.6+7-1~22.04.1) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/java to provide /usr/bin/java (java) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jpackage to provide /usr/bin/jpackage (jpackage) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/keytool to provide /usr/bin/keytool (keytool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/rmiregistry to provide /usr/bin/rmiregistry (rmiregistry) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/lib/jexec to provide /usr/bin/jexec (jexec) in auto mode\n",
            "Setting up libice-dev:amd64 (2:1.0.10-1build2) ...\n",
            "Setting up libsm-dev:amd64 (2:1.2.3-1build2) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
            "Setting up openjdk-21-jre:amd64 (21.0.6+7-1~22.04.1) ...\n",
            "Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Setting up libxt-dev:amd64 (1:1.2.1-1) ...\n",
            "Setting up fonts-dejavu-core (2.37-2build1) ...\n",
            "Setting up fonts-dejavu-extra (2.37-2build1) ...\n",
            "Setting up libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Setting up openjdk-21-jdk-headless:amd64 (21.0.6+7-1~22.04.1) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jar to provide /usr/bin/jar (jar) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jarsigner to provide /usr/bin/jarsigner (jarsigner) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/javac to provide /usr/bin/javac (javac) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/javadoc to provide /usr/bin/javadoc (javadoc) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/javap to provide /usr/bin/javap (javap) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jcmd to provide /usr/bin/jcmd (jcmd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jdb to provide /usr/bin/jdb (jdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jdeprscan to provide /usr/bin/jdeprscan (jdeprscan) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jdeps to provide /usr/bin/jdeps (jdeps) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jfr to provide /usr/bin/jfr (jfr) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jimage to provide /usr/bin/jimage (jimage) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jinfo to provide /usr/bin/jinfo (jinfo) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jlink to provide /usr/bin/jlink (jlink) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jmap to provide /usr/bin/jmap (jmap) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jmod to provide /usr/bin/jmod (jmod) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jps to provide /usr/bin/jps (jps) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jrunscript to provide /usr/bin/jrunscript (jrunscript) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jshell to provide /usr/bin/jshell (jshell) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jstack to provide /usr/bin/jstack (jstack) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jstat to provide /usr/bin/jstat (jstat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jstatd to provide /usr/bin/jstatd (jstatd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jwebserver to provide /usr/bin/jwebserver (jwebserver) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/serialver to provide /usr/bin/serialver (serialver) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jhsdb to provide /usr/bin/jhsdb (jhsdb) in auto mode\n",
            "Setting up openjdk-21-jdk:amd64 (21.0.6+7-1~22.04.1) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-21-openjdk-amd64/bin/jconsole to provide /usr/bin/jconsole (jconsole) in auto mode\n",
            "Setting up x11-utils (7.7+5build2) ...\n",
            "Setting up libatk-wrapper-java (0.38.0-5build1) ...\n",
            "Setting up libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!wget \"https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/3.3.4/hadoop-aws-3.3.4.jar\" -P \"spark/lib-jars/\"\n",
        "!wget \"https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.12.699/aws-java-sdk-bundle-1.12.699.jar\" -P \"spark/lib-jars/\"\n",
        "!wget \"https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk/1.12.699/aws-java-sdk-1.12.699.jar\" -P \"spark/lib-jars/\"\n",
        "!wget \"https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-core/1.12.699/aws-java-sdk-core-1.12.699.jar\" -P \"spark/lib-jars/\"\n",
        "!wget \"https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-s3/1.12.699/aws-java-sdk-s3-1.12.699.jar\" -P \"spark/lib-jars/\""
      ],
      "metadata": {
        "collapsed": true,
        "id": "kxGSoMTz_9Ce"
      },
      "id": "kxGSoMTz_9Ce",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!java --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTK3BZ8ZVfcZ",
        "outputId": "16c48264-1efe-4acd-da3b-3fd2e6abf2c2"
      },
      "id": "pTK3BZ8ZVfcZ",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "openjdk 21.0.6 2025-01-21\n",
            "OpenJDK Runtime Environment (build 21.0.6+7-Ubuntu-122.04.1)\n",
            "OpenJDK 64-Bit Server VM (build 21.0.6+7-Ubuntu-122.04.1, mixed mode, sharing)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:  # When on Google Colab, clone the repository to download any necessary cache.\n",
        "    import google.colab\n",
        "    repo_path = 'cdd'\n",
        "    !git -C $repo_path pull origin || git clone https://github.com/hygo2025/cdd-projeto-final.git $repo_path\n",
        "except:\n",
        "    repo_path = '.'  # Use the local path if not on Google Colab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elmgBR9pVh0g",
        "outputId": "aac00f40-417e-4fc0-935b-797feac6d8e6"
      },
      "id": "elmgBR9pVh0g",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: cannot change to 'cdd': No such file or directory\n",
            "Cloning into 'cdd'...\n",
            "remote: Enumerating objects: 198, done.\u001b[K\n",
            "remote: Counting objects: 100% (198/198), done.\u001b[K\n",
            "remote: Compressing objects: 100% (126/126), done.\u001b[K\n",
            "remote: Total 198 (delta 104), reused 150 (delta 64), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (198/198), 80.19 KiB | 1.60 MiB/s, done.\n",
            "Resolving deltas: 100% (104/104), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install -r cdd/requirements.txt"
      ],
      "metadata": {
        "id": "mTfu6fnAVkYc"
      },
      "id": "mTfu6fnAVkYc",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "import pkg_resources\n",
        "!pip install -e $repo_path"
      ],
      "metadata": {
        "id": "GAgHJ4f8VtHP"
      },
      "id": "GAgHJ4f8VtHP",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# configurar as variáveis de ambiente\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-21-openjdk-amd64\"\n",
        "\n",
        "os.environ[\"SPARK_DRIVER_EXTRACLASSPATH\"] = \"/content/spark/lib-jars/*\"\n",
        "os.environ[\"SPARK_EXECUTOR_EXTRACLASSPATH\"] = \"/content/spark/lib-jars/*\"\n",
        "os.environ[\"SPARK_SERIALIZER\"] = \"org.apache.spark.serializer.KryoSerializer\"\n",
        "os.environ[\"ENV\"] = \"dev\"\n",
        "os.environ[\"PYTHONUNBUFFERED\"] = \"1\"\n",
        "os.environ[\"SPARK_EXECUTOR_MEMORY\"] = \"78g\"\n",
        "os.environ[\"SPARK_DRIVER_MEMORY\"] = \"78g\"\n",
        "os.environ[\"SPARK_MEMORY_FRACTION\"] = \"0.8\"\n",
        "\n",
        "\n",
        "os.environ[\"DOWNLOAD_FOLDER\"] = \"/content/datasets\""
      ],
      "metadata": {
        "id": "H939YnnX-A3D"
      },
      "id": "H939YnnX-A3D",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "V4DTuR9P--H2"
      },
      "id": "V4DTuR9P--H2",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:  # When on Google Colab, clone the repository to download any necessary cache.\n",
        "    import google.colab\n",
        "    repo_path = 'cdd'\n",
        "    !git -C $repo_path pull origin || git clone https://github.com/hygo2025/cdd-projeto-final.git $repo_path\n",
        "except:\n",
        "    repo_path = '.'  # Use the local path if not on Google Colab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4xGPDpcYBHmU",
        "outputId": "28c4c0c6-7551-4612-e42c-bc1030430ebb"
      },
      "id": "4xGPDpcYBHmU",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "import pkg_resources\n",
        "\n",
        "if repo_path not in sys.path:\n",
        "    sys.path.append(repo_path)"
      ],
      "metadata": {
        "id": "xPE1A11QBnM9"
      },
      "id": "xPE1A11QBnM9",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cdd"
      ],
      "metadata": {
        "id": "n6dYXTkxFlEF"
      },
      "id": "n6dYXTkxFlEF",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "full_results = pd.DataFrame()"
      ],
      "metadata": {
        "id": "oib-FQl_cw0W"
      },
      "id": "oib-FQl_cw0W",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from src.sar_model import SarModel\n",
        "from src.utils.enums import MovieLensDataset, SimilarityType\n",
        "\n",
        "def evaluate_sar():\n",
        "    top_k = 10\n",
        "    validate_size = 0.25\n",
        "    time_decay_coefficient = 30\n",
        "    seed = 42\n",
        "    df_results = pd.DataFrame()\n",
        "\n",
        "\n",
        "    # Iterando sobre todas as similaridades definidas na enumeração\n",
        "    for similarity in SimilarityType:\n",
        "        print(f\"\\nTestando similaridade: {similarity.value}\")\n",
        "\n",
        "        # Instanciando o modelo com a similaridade atual\n",
        "        sar_model = SarModel(\n",
        "            dataset=MovieLensDataset.ML_1M,\n",
        "            top_k=top_k,\n",
        "            validate_size=validate_size,\n",
        "            time_decay_coefficient=time_decay_coefficient,\n",
        "            similarity_type=similarity,\n",
        "            seed=seed\n",
        "        )\n",
        "\n",
        "        # Avaliando o modelo\n",
        "        result = sar_model.evaluate()\n",
        "\n",
        "        result['version'] = f\"similarity_{similarity.value}_top_k_{top_k}_validate_size_{validate_size}_time_decay_coefficient_{time_decay_coefficient}\"\n",
        "        result['algorithm'] = 'sar'\n",
        "\n",
        "        df_results = pd.concat([df_results, result], ignore_index=True)\n",
        "\n",
        "        print(f\"Resultado para similaridade {similarity.value}:\")\n",
        "        print(result)\n",
        "    return df_results\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "H1K9GdD8QYrk",
        "outputId": "354f122a-148e-43b5-fa19-2344b53fe0ac"
      },
      "id": "H1K9GdD8QYrk",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'recommenders'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-e069ed3d5af9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msar_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSarModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menums\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMovieLensDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSimilarityType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_sar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/cdd/src/sar_model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mrecommenders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_splitters\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpython_stratified_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrecommenders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msar\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSAR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'recommenders'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sar_results = evaluate_sar()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "211XIAhvV6jM"
      },
      "id": "211XIAhvV6jM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_results = pd.concat([full_results, sar_results], ignore_index=True)\n",
        "full_results.to_csv('01_sar.csv', index=False)"
      ],
      "metadata": {
        "id": "XthPbpk3c15N"
      },
      "id": "XthPbpk3c15N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import pandas as pd\n",
        "from src.utils.enums import MovieLensDataset\n",
        "from src.als_model import SparkAlsModel\n",
        "\n",
        "def evaluate_als(spark):\n",
        "    # Definindo os grids de parâmetros\n",
        "    max_iter_options = [20]\n",
        "    rank_options = [10, 20, 30, 40]\n",
        "    reg_param_options = [0.05]\n",
        "    alpha_options = [0.1]\n",
        "\n",
        "    # Parâmetros fixos\n",
        "    validate_size = 0.25\n",
        "    top_k = 10\n",
        "    seed = 42\n",
        "    dataset = MovieLensDataset.ML_1M\n",
        "\n",
        "    # Cria um DataFrame vazio para armazenar os resultados\n",
        "    df_results = pd.DataFrame()\n",
        "\n",
        "    # Itera por todas as combinações de parâmetros\n",
        "    for max_iter, rank, reg_param, alpha in itertools.product(\n",
        "            max_iter_options, rank_options, reg_param_options, alpha_options\n",
        "    ):\n",
        "        print(f\"\\nTestando: maxIter={max_iter}, rank={rank}, regParam={reg_param}, alpha={alpha}\")\n",
        "\n",
        "        # Instanciando o modelo ALS com a configuração atual\n",
        "        als_model = SparkAlsModel(\n",
        "            spark=spark,\n",
        "            dataset=dataset,\n",
        "            max_iter=max_iter,\n",
        "            rank=rank,\n",
        "            reg_param=reg_param,\n",
        "            alpha=alpha,\n",
        "            validate_size=validate_size,\n",
        "            top_k=top_k,\n",
        "            seed=seed\n",
        "        )\n",
        "\n",
        "\n",
        "        # Avaliando o modelo\n",
        "        result = als_model.evaluate()\n",
        "\n",
        "        # Adiciona as informações desejadas\n",
        "        result['algorithm'] = 'als'\n",
        "        result['version'] = f\"max_iter_{max_iter}_rank_{rank}_reg_param_{reg_param}_alpha_{alpha}\"\n",
        "\n",
        "        df_results = pd.concat([df_results, result], ignore_index=True)\n",
        "        print(f\"Resultado: {result}\")\n",
        "\n",
        "\n",
        "    return df_results"
      ],
      "metadata": {
        "id": "BjUzjxEKZAKE"
      },
      "id": "BjUzjxEKZAKE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from src.utils.spark_session_utils import create_spark_session\n",
        "\n",
        "spark = create_spark_session(\"ALS\")\n",
        "als_result = evaluate_als(spark)"
      ],
      "metadata": {
        "id": "HX3T0HZwcNDJ"
      },
      "id": "HX3T0HZwcNDJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_results = pd.concat([full_results, als_result], ignore_index=True)\n",
        "full_results.to_csv('02_sar_als.csv', index=False)"
      ],
      "metadata": {
        "id": "tTfNcFiBvYKo"
      },
      "id": "tTfNcFiBvYKo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import pandas as pd\n",
        "from src.utils.enums import MovieLensDataset\n",
        "from src.ncf_model import NcfModel\n",
        "\n",
        "def evaluate_ncf():\n",
        "    # Parâmetros a serem testados\n",
        "    n_factors_options = [4]\n",
        "    batch_size_options = [256, 512]\n",
        "    lr_options = [1e-3]\n",
        "    epochs_options = [10, 15]\n",
        "\n",
        "    # Parâmetros fixos\n",
        "    layer_sizes = [16, 8, 4]\n",
        "    top_k = 10\n",
        "    test_size = 0.25\n",
        "    seed = 42\n",
        "    dataset = MovieLensDataset.ML_1M\n",
        "\n",
        "    # Cria um DataFrame vazio para armazenar os resultados\n",
        "    df_results = pd.DataFrame()\n",
        "\n",
        "    # Itera por todas as combinações de parâmetros\n",
        "    for n_factors, batch_size, lr, epochs in itertools.product(\n",
        "        n_factors_options, batch_size_options, lr_options, epochs_options\n",
        "    ):\n",
        "        print(f\"\\nTestando: n_factors={n_factors}, batch_size={batch_size}, lr={lr}, epochs={epochs}\")\n",
        "\n",
        "        # Instancia o modelo NCF com a configuração atual\n",
        "        model = NcfModel(\n",
        "            dataset=dataset,\n",
        "            n_factors=n_factors,\n",
        "            batch_size=batch_size,\n",
        "            lr=lr,\n",
        "            layer_sizes=layer_sizes,\n",
        "            epochs=epochs,\n",
        "            top_k=top_k,\n",
        "            test_size=test_size,\n",
        "            seed=seed\n",
        "        )\n",
        "\n",
        "        # Avalia o modelo\n",
        "        result = model.evaluate()\n",
        "\n",
        "        # Adiciona informações de identificação\n",
        "        result['algorithm'] = 'ncf'\n",
        "        result['version'] = f\"n_factors_{n_factors}_batch_size_{batch_size}_lr_{lr}_epochs_{epochs}\"\n",
        "\n",
        "        df_results = pd.concat([df_results, result], ignore_index=True)\n",
        "\n",
        "        print(f\"Resultado: {result}\")\n",
        "\n",
        "    return df_results"
      ],
      "metadata": {
        "id": "YxsLihPdpeCk"
      },
      "id": "YxsLihPdpeCk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ncf_result = evaluate_ncf()"
      ],
      "metadata": {
        "id": "YhQkGyPRuAGH"
      },
      "id": "YhQkGyPRuAGH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_results = pd.concat([full_results, ncf_result], ignore_index=True)\n",
        "full_results.to_csv('03_sar_als_ncf.csv', index=False)"
      ],
      "metadata": {
        "id": "6A408Ba9t_H5"
      },
      "id": "6A408Ba9t_H5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import pandas as pd\n",
        "from src.utils.enums import MovieLensDataset\n",
        "from src.bivae_model import BivaeModel\n",
        "\n",
        "def evaluate_bivae():\n",
        "    # Parâmetros a serem testados\n",
        "    latent_dim_options = [50, 100]\n",
        "    epochs_options = [300, 500]\n",
        "    lr_options = [0.001]\n",
        "\n",
        "    # Parâmetros fixos\n",
        "    top_k = 10\n",
        "    batch_size = 1024\n",
        "    encoder_dims = [100]\n",
        "    act_func = 'tanh'\n",
        "    likelihood = 'pois'\n",
        "    test_size = 0.25\n",
        "    seed = 42\n",
        "    dataset = MovieLensDataset.ML_1M\n",
        "\n",
        "    # Cria um DataFrame vazio para armazenar os resultados\n",
        "    df_results = pd.DataFrame()\n",
        "\n",
        "    # Itera por todas as combinações de parâmetros\n",
        "    for latent_dim, epochs, lr in itertools.product(\n",
        "        latent_dim_options, epochs_options, lr_options\n",
        "    ):\n",
        "        print(f\"\\nTestando: latent_dim={latent_dim}, epochs={epochs}, lr={lr}\")\n",
        "\n",
        "        # Instancia o modelo BivaeModel com a configuração atual\n",
        "        model = BivaeModel(\n",
        "            dataset=dataset,\n",
        "            top_k=top_k,\n",
        "            batch_size=batch_size,\n",
        "            latent_dim=latent_dim,\n",
        "            encoder_dims=encoder_dims,\n",
        "            act_func=act_func,\n",
        "            likelihood=likelihood,\n",
        "            epochs=epochs,\n",
        "            lr=lr,\n",
        "            test_size=test_size,\n",
        "            seed=seed\n",
        "        )\n",
        "\n",
        "        # Avalia o modelo\n",
        "        result = model.evaluate()\n",
        "\n",
        "        # Adiciona informações de identificação\n",
        "        result['algorithm'] = 'bivae'\n",
        "        result['version'] = f\"latent_dim_{latent_dim}_epochs_{epochs}_lr_{lr}\"\n",
        "\n",
        "        # Converte o dicionário de resultado em um DataFrame de uma linha e concatena\n",
        "        df_results = pd.concat([df_results, pd.DataFrame([result])], ignore_index=True)\n",
        "\n",
        "        print(f\"Resultado: {result}\")\n",
        "\n",
        "    return df_results\n"
      ],
      "metadata": {
        "id": "VO6C4c6CqQzu"
      },
      "id": "VO6C4c6CqQzu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bivae_result = evaluate_bivae()"
      ],
      "metadata": {
        "id": "lh2QVxKLvogc"
      },
      "id": "lh2QVxKLvogc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_results = pd.concat([full_results, bivae_result], ignore_index=True)\n",
        "full_results.to_csv('04_sar_als_ncf_bivae.csv', index=False)"
      ],
      "metadata": {
        "id": "OZW50DFtvpAE"
      },
      "id": "OZW50DFtvpAE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import pandas as pd\n",
        "from src.utils.enums import MovieLensDataset\n",
        "from src.light_gcn_model import LightGcnModel\n",
        "\n",
        "def evaluate_lightgcn():\n",
        "    # Parâmetros a serem testados\n",
        "    n_layers_options = [2, 3, 4]\n",
        "    lr_options = [0.005, 0.01]\n",
        "    epochs_options = [1, 5]\n",
        "\n",
        "    # Parâmetros fixos\n",
        "    batch_size = 1024\n",
        "    top_k = 10\n",
        "    test_size = 0.2\n",
        "    seed = 42\n",
        "    dataset = MovieLensDataset.ML_1M\n",
        "\n",
        "    # Cria um DataFrame vazio para armazenar os resultados\n",
        "    df_results = pd.DataFrame()\n",
        "\n",
        "    # Itera por todas as combinações de parâmetros\n",
        "    for n_layers, lr, epochs in itertools.product(n_layers_options, lr_options, epochs_options):\n",
        "        print(f\"\\nTestando: n_layers={n_layers}, lr={lr}, epochs={epochs}\")\n",
        "\n",
        "        # Instancia o modelo LightGcnModel com a configuração atual\n",
        "        model = LightGcnModel(\n",
        "            dataset=dataset,\n",
        "            n_layers=n_layers,\n",
        "            batch_size=batch_size,\n",
        "            lr=lr,\n",
        "            epochs=epochs,\n",
        "            top_k=top_k,\n",
        "            test_size=test_size,\n",
        "            seed=seed\n",
        "        )\n",
        "\n",
        "        # Avalia o modelo\n",
        "        result = model.evaluate()\n",
        "\n",
        "        # Adiciona informações de identificação\n",
        "        result['algorithm'] = 'lightgcn'\n",
        "        result['version'] = f\"n_layers_{n_layers}_lr_{lr}_epochs_{epochs}\"\n",
        "\n",
        "        # Converte o dicionário de resultado em um DataFrame de uma linha e concatena\n",
        "        df_results = pd.concat([df_results, pd.DataFrame([result])], ignore_index=True)\n",
        "\n",
        "        print(f\"Resultado: {result}\")\n",
        "\n",
        "    return df_results\n"
      ],
      "metadata": {
        "id": "Xih-qDW4qbEx"
      },
      "id": "Xih-qDW4qbEx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lightgcn_result = evaluate_lightgcn()"
      ],
      "metadata": {
        "id": "gN0D_3ahvvJI"
      },
      "id": "gN0D_3ahvvJI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_results = pd.concat([full_results, lightgcn_result], ignore_index=True)\n",
        "full_results.to_csv('05_sar_als_ncf_bivae_lightgcn.csv', index=False)"
      ],
      "metadata": {
        "id": "0R6MBN0rvu_p"
      },
      "id": "0R6MBN0rvu_p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import pandas as pd\n",
        "from src.utils.enums import MovieLensDataset\n",
        "from src.fastai_model import FastAiModel\n",
        "\n",
        "def evaluate_fastai():\n",
        "    # Parâmetros a serem testados\n",
        "    n_factors_options = [40, 50]\n",
        "    epochs_options = [1, 2]\n",
        "\n",
        "    # Parâmetros fixos\n",
        "    test_size = 0.25\n",
        "    top_k = 10\n",
        "    seed = 42\n",
        "    dataset = MovieLensDataset.ML_1M\n",
        "\n",
        "    # Cria um DataFrame vazio para armazenar os resultados\n",
        "    df_results = pd.DataFrame()\n",
        "\n",
        "    # Itera por todas as combinações de parâmetros\n",
        "    for n_factors, epochs in itertools.product(n_factors_options, epochs_options):\n",
        "        print(f\"\\nTestando: n_factors={n_factors}, epochs={epochs}\")\n",
        "\n",
        "        # Instancia o modelo FastAiModel com a configuração atual\n",
        "        model = FastAiModel(\n",
        "            dataset=dataset,\n",
        "            n_factors=n_factors,\n",
        "            test_size=test_size,\n",
        "            epochs=epochs,\n",
        "            top_k=top_k,\n",
        "            seed=seed\n",
        "        )\n",
        "\n",
        "        # Avalia o modelo\n",
        "        result = model.evaluate()\n",
        "\n",
        "        # Adiciona informações de identificação\n",
        "        result['algorithm'] = 'fastai'\n",
        "        result['version'] = f\"n_factors_{n_factors}_epochs_{epochs}\"\n",
        "\n",
        "        # Converte o dicionário de resultado em um DataFrame de uma linha e concatena\n",
        "        df_results = pd.concat([df_results, pd.DataFrame([result])], ignore_index=True)\n",
        "\n",
        "        print(f\"Resultado: {result}\")\n",
        "\n",
        "    return df_results\n"
      ],
      "metadata": {
        "id": "qmaQVlkUqeKn"
      },
      "id": "qmaQVlkUqeKn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fastai_result = evaluate_fastai()"
      ],
      "metadata": {
        "id": "AfhvDeV7vxM3"
      },
      "id": "AfhvDeV7vxM3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_results = pd.concat([full_results, fastai_result], ignore_index=True)\n",
        "full_results.to_csv('06_sar_als_ncf_bivae_lightgcn_fastai.csv', index=False)"
      ],
      "metadata": {
        "id": "SW91q2BzvxrN"
      },
      "id": "SW91q2BzvxrN",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}