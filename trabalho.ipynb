{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# Install java\n",
        "!apt install openjdk-21-jdk"
      ],
      "metadata": {
        "collapsed": true,
        "id": "mE1noAqF9PdU"
      },
      "id": "mE1noAqF9PdU",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!wget \"https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/3.3.4/hadoop-aws-3.3.4.jar\" -P \"spark/lib-jars/\"\n",
        "!wget \"https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.12.699/aws-java-sdk-bundle-1.12.699.jar\" -P \"spark/lib-jars/\"\n",
        "!wget \"https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk/1.12.699/aws-java-sdk-1.12.699.jar\" -P \"spark/lib-jars/\"\n",
        "!wget \"https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-core/1.12.699/aws-java-sdk-core-1.12.699.jar\" -P \"spark/lib-jars/\"\n",
        "!wget \"https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-s3/1.12.699/aws-java-sdk-s3-1.12.699.jar\" -P \"spark/lib-jars/\""
      ],
      "metadata": {
        "collapsed": true,
        "id": "kxGSoMTz_9Ce"
      },
      "id": "kxGSoMTz_9Ce",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!java --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTK3BZ8ZVfcZ",
        "outputId": "3d669740-d286-42eb-d493-127d47dca2f9"
      },
      "id": "pTK3BZ8ZVfcZ",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "openjdk 21.0.6 2025-01-21\n",
            "OpenJDK Runtime Environment (build 21.0.6+7-Ubuntu-122.04.1)\n",
            "OpenJDK 64-Bit Server VM (build 21.0.6+7-Ubuntu-122.04.1, mixed mode, sharing)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:  # When on Google Colab, clone the repository to download any necessary cache.\n",
        "    import google.colab\n",
        "    repo_path = 'cdd'\n",
        "    !git -C $repo_path pull origin || git clone https://github.com/hygo2025/cdd-projeto-final.git $repo_path\n",
        "except:\n",
        "    repo_path = '.'  # Use the local path if not on Google Colab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elmgBR9pVh0g",
        "outputId": "1dba21ae-5aee-44d8-ec07-fdcd64717192"
      },
      "id": "elmgBR9pVh0g",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: cannot change to 'cdd': No such file or directory\n",
            "Cloning into 'cdd'...\n",
            "remote: Enumerating objects: 211, done.\u001b[K\n",
            "remote: Counting objects: 100% (211/211), done.\u001b[K\n",
            "remote: Compressing objects: 100% (138/138), done.\u001b[K\n",
            "remote: Total 211 (delta 112), reused 155 (delta 65), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (211/211), 93.49 KiB | 5.84 MiB/s, done.\n",
            "Resolving deltas: 100% (112/112), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%capture\n",
        "!pip install -r cdd/requirements.txt"
      ],
      "metadata": {
        "id": "mTfu6fnAVkYc"
      },
      "id": "mTfu6fnAVkYc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%capture\n",
        "import pkg_resources\n",
        "!pip install -e $repo_path"
      ],
      "metadata": {
        "id": "GAgHJ4f8VtHP"
      },
      "id": "GAgHJ4f8VtHP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# configurar as variáveis de ambiente\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-21-openjdk-amd64\"\n",
        "\n",
        "os.environ[\"SPARK_DRIVER_EXTRACLASSPATH\"] = \"/content/spark/lib-jars/*\"\n",
        "os.environ[\"SPARK_EXECUTOR_EXTRACLASSPATH\"] = \"/content/spark/lib-jars/*\"\n",
        "os.environ[\"SPARK_SERIALIZER\"] = \"org.apache.spark.serializer.KryoSerializer\"\n",
        "os.environ[\"ENV\"] = \"dev\"\n",
        "os.environ[\"PYTHONUNBUFFERED\"] = \"1\"\n",
        "os.environ[\"SPARK_EXECUTOR_MEMORY\"] = \"8g\"\n",
        "os.environ[\"SPARK_DRIVER_MEMORY\"] = \"8g\"\n",
        "os.environ[\"SPARK_MEMORY_FRACTION\"] = \"0.8\"\n",
        "\n",
        "\n",
        "os.environ[\"DOWNLOAD_FOLDER\"] = \"/content/datasets\""
      ],
      "metadata": {
        "id": "H939YnnX-A3D"
      },
      "id": "H939YnnX-A3D",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "V4DTuR9P--H2"
      },
      "id": "V4DTuR9P--H2",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:  # When on Google Colab, clone the repository to download any necessary cache.\n",
        "    import google.colab\n",
        "    repo_path = 'cdd'\n",
        "    !git -C $repo_path pull origin || git clone https://github.com/hygo2025/cdd-projeto-final.git $repo_path\n",
        "except:\n",
        "    repo_path = '.'  # Use the local path if not on Google Colab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4xGPDpcYBHmU",
        "outputId": "d881bcdd-99b2-4666-b8ef-310923c0410c"
      },
      "id": "4xGPDpcYBHmU",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "import pkg_resources\n",
        "\n",
        "if repo_path not in sys.path:\n",
        "    sys.path.append(repo_path)"
      ],
      "metadata": {
        "id": "xPE1A11QBnM9"
      },
      "id": "xPE1A11QBnM9",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cdd"
      ],
      "metadata": {
        "id": "n6dYXTkxFlEF"
      },
      "id": "n6dYXTkxFlEF",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "full_results = pd.DataFrame()"
      ],
      "metadata": {
        "id": "oib-FQl_cw0W"
      },
      "id": "oib-FQl_cw0W",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from src.sar_model import SarModel\n",
        "from src.utils.enums import MovieLensDataset, SimilarityType\n",
        "\n",
        "def evaluate_sar():\n",
        "    top_k = 10\n",
        "    validate_size = 0.25\n",
        "    time_decay_coefficient = 30\n",
        "    seed = 42\n",
        "    df_results = pd.DataFrame()\n",
        "\n",
        "\n",
        "    # Iterando sobre todas as similaridades definidas na enumeração\n",
        "    for similarity in SimilarityType:\n",
        "        print(f\"\\nTestando similaridade: {similarity.value}\")\n",
        "\n",
        "        # Instanciando o modelo com a similaridade atual\n",
        "        sar_model = SarModel(\n",
        "            dataset=MovieLensDataset.ML_1M,\n",
        "            top_k=top_k,\n",
        "            validate_size=validate_size,\n",
        "            time_decay_coefficient=time_decay_coefficient,\n",
        "            similarity_type=similarity,\n",
        "            seed=seed\n",
        "        )\n",
        "\n",
        "        # Avaliando o modelo\n",
        "        result = sar_model.evaluate()\n",
        "\n",
        "        result['version'] = f\"similarity_{similarity.value}_top_k_{top_k}_validate_size_{validate_size}_time_decay_coefficient_{time_decay_coefficient}\"\n",
        "        result['algorithm'] = 'sar'\n",
        "\n",
        "        df_results = pd.concat([df_results, result], ignore_index=True)\n",
        "\n",
        "        print(f\"Resultado para similaridade {similarity.value}:\")\n",
        "        print(result)\n",
        "    return df_results\n"
      ],
      "metadata": {
        "id": "H1K9GdD8QYrk"
      },
      "id": "H1K9GdD8QYrk",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sar_results = evaluate_sar()"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "211XIAhvV6jM",
        "outputId": "63266398-71d3-4c15-f95a-7284d0f3280a"
      },
      "id": "211XIAhvV6jM",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testando similaridade: cooccurrence\n",
            "Inicializando SarModel...\n",
            "Carregando e preparando os dados...\n",
            "/content/datasets\n",
            "ML_1M\n",
            "Dataset ML_1M não encontrado em /content/datasets/ML_1M. Iniciando download e extração...\n",
            "Iniciando download de: https://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
            "Progresso: 100.00%\n",
            "Download concluído.\n",
            "Descompactando /content/datasets/ml-1m.zip para /content/datasets/ML_1M...\n",
            "Descompactação concluída.\n",
            "/content/datasets\n",
            "ML_1M\n",
            "Dados carregados: 1000209 linhas.\n",
            "Dividindo os dados em treino e teste com python_stratified_split...\n",
            "Conjunto de treino: 750121 linhas, Conjunto de teste: 250088 linhas.\n",
            "Iniciando o processo de avaliação do modelo SAR...\n",
            "Iniciando o processo de predição com o modelo SAR...\n",
            "Iniciando treinamento do modelo SAR...\n",
            "Treinamento concluído. Salvando o modelo...\n",
            "Modelo salvo em: ../data/sar/movielens_sar_model_time_decay_coefficient_30_similarity_type_SimilarityType.COCCURRENCE_top_k_10.model\n",
            "Modelo SAR treinado e salvo com sucesso.\n",
            "Gerando recomendações (removendo itens já vistos)...\n",
            "Juntando títulos dos itens às recomendações...\n",
            "Processo de predição concluído.\n",
            "Calculando métricas de avaliação (ranking)...\n",
            "Avaliação concluída.\n",
            "Resultado para similaridade cooccurrence:\n",
            "        MAP    nDCG@K  Precision@K  Recall@K  \\\n",
            "0  0.173259  0.281954     0.252086  0.082533   \n",
            "\n",
            "                                             version algorithm  \n",
            "0  similarity_cooccurrence_top_k_10_validate_size...       sar  \n",
            "\n",
            "Testando similaridade: cosine\n",
            "Inicializando SarModel...\n",
            "Carregando e preparando os dados...\n",
            "/content/datasets\n",
            "ML_1M\n",
            "/content/datasets\n",
            "ML_1M\n",
            "Dados carregados: 1000209 linhas.\n",
            "Dividindo os dados em treino e teste com python_stratified_split...\n",
            "Conjunto de treino: 750121 linhas, Conjunto de teste: 250088 linhas.\n",
            "Iniciando o processo de avaliação do modelo SAR...\n",
            "Iniciando o processo de predição com o modelo SAR...\n",
            "Iniciando treinamento do modelo SAR...\n",
            "Treinamento concluído. Salvando o modelo...\n",
            "Modelo salvo em: ../data/sar/movielens_sar_model_time_decay_coefficient_30_similarity_type_SimilarityType.COSINE_top_k_10.model\n",
            "Modelo SAR treinado e salvo com sucesso.\n",
            "Gerando recomendações (removendo itens já vistos)...\n",
            "Juntando títulos dos itens às recomendações...\n",
            "Processo de predição concluído.\n",
            "Calculando métricas de avaliação (ranking)...\n",
            "Avaliação concluída.\n",
            "Resultado para similaridade cosine:\n",
            "        MAP   nDCG@K  Precision@K  Recall@K  \\\n",
            "0  0.219533  0.34561     0.307864  0.114765   \n",
            "\n",
            "                                             version algorithm  \n",
            "0  similarity_cosine_top_k_10_validate_size_0.25_...       sar  \n",
            "\n",
            "Testando similaridade: inclusion index\n",
            "Inicializando SarModel...\n",
            "Carregando e preparando os dados...\n",
            "/content/datasets\n",
            "ML_1M\n",
            "/content/datasets\n",
            "ML_1M\n",
            "Dados carregados: 1000209 linhas.\n",
            "Dividindo os dados em treino e teste com python_stratified_split...\n",
            "Conjunto de treino: 750121 linhas, Conjunto de teste: 250088 linhas.\n",
            "Iniciando o processo de avaliação do modelo SAR...\n",
            "Iniciando o processo de predição com o modelo SAR...\n",
            "Iniciando treinamento do modelo SAR...\n",
            "Treinamento concluído. Salvando o modelo...\n",
            "Modelo salvo em: ../data/sar/movielens_sar_model_time_decay_coefficient_30_similarity_type_SimilarityType.INCLUSION_INDEX_top_k_10.model\n",
            "Modelo SAR treinado e salvo com sucesso.\n",
            "Gerando recomendações (removendo itens já vistos)...\n",
            "Juntando títulos dos itens às recomendações...\n",
            "Processo de predição concluído.\n",
            "Calculando métricas de avaliação (ranking)...\n",
            "Avaliação concluída.\n",
            "Resultado para similaridade inclusion index:\n",
            "       MAP    nDCG@K  Precision@K  Recall@K  \\\n",
            "0  0.00692  0.020386     0.025563  0.005893   \n",
            "\n",
            "                                             version algorithm  \n",
            "0  similarity_inclusion index_top_k_10_validate_s...       sar  \n",
            "\n",
            "Testando similaridade: jaccard\n",
            "Inicializando SarModel...\n",
            "Carregando e preparando os dados...\n",
            "/content/datasets\n",
            "ML_1M\n",
            "/content/datasets\n",
            "ML_1M\n",
            "Dados carregados: 1000209 linhas.\n",
            "Dividindo os dados em treino e teste com python_stratified_split...\n",
            "Conjunto de treino: 750121 linhas, Conjunto de teste: 250088 linhas.\n",
            "Iniciando o processo de avaliação do modelo SAR...\n",
            "Iniciando o processo de predição com o modelo SAR...\n",
            "Iniciando treinamento do modelo SAR...\n",
            "Treinamento concluído. Salvando o modelo...\n",
            "Modelo salvo em: ../data/sar/movielens_sar_model_time_decay_coefficient_30_similarity_type_SimilarityType.JACCARD_top_k_10.model\n",
            "Modelo SAR treinado e salvo com sucesso.\n",
            "Gerando recomendações (removendo itens já vistos)...\n",
            "Juntando títulos dos itens às recomendações...\n",
            "Processo de predição concluído.\n",
            "Calculando métricas de avaliação (ranking)...\n",
            "Avaliação concluída.\n",
            "Resultado para similaridade jaccard:\n",
            "        MAP    nDCG@K  Precision@K  Recall@K  \\\n",
            "0  0.185099  0.309862     0.279222  0.109562   \n",
            "\n",
            "                                             version algorithm  \n",
            "0  similarity_jaccard_top_k_10_validate_size_0.25...       sar  \n",
            "\n",
            "Testando similaridade: lexicographers mutual information\n",
            "Inicializando SarModel...\n",
            "Carregando e preparando os dados...\n",
            "/content/datasets\n",
            "ML_1M\n",
            "/content/datasets\n",
            "ML_1M\n",
            "Dados carregados: 1000209 linhas.\n",
            "Dividindo os dados em treino e teste com python_stratified_split...\n",
            "Conjunto de treino: 750121 linhas, Conjunto de teste: 250088 linhas.\n",
            "Iniciando o processo de avaliação do modelo SAR...\n",
            "Iniciando o processo de predição com o modelo SAR...\n",
            "Iniciando treinamento do modelo SAR...\n",
            "Treinamento concluído. Salvando o modelo...\n",
            "Modelo salvo em: ../data/sar/movielens_sar_model_time_decay_coefficient_30_similarity_type_SimilarityType.LEXICOGRAPHERS_MUTUAL_INFORMATION_top_k_10.model\n",
            "Modelo SAR treinado e salvo com sucesso.\n",
            "Gerando recomendações (removendo itens já vistos)...\n",
            "Juntando títulos dos itens às recomendações...\n",
            "Processo de predição concluído.\n",
            "Calculando métricas de avaliação (ranking)...\n",
            "Avaliação concluída.\n",
            "Resultado para similaridade lexicographers mutual information:\n",
            "   MAP  nDCG@K  Precision@K  Recall@K  \\\n",
            "0  0.0     0.0          0.0       0.0   \n",
            "\n",
            "                                             version algorithm  \n",
            "0  similarity_lexicographers mutual information_t...       sar  \n",
            "\n",
            "Testando similaridade: lift\n",
            "Inicializando SarModel...\n",
            "Carregando e preparando os dados...\n",
            "/content/datasets\n",
            "ML_1M\n",
            "/content/datasets\n",
            "ML_1M\n",
            "Dados carregados: 1000209 linhas.\n",
            "Dividindo os dados em treino e teste com python_stratified_split...\n",
            "Conjunto de treino: 750121 linhas, Conjunto de teste: 250088 linhas.\n",
            "Iniciando o processo de avaliação do modelo SAR...\n",
            "Iniciando o processo de predição com o modelo SAR...\n",
            "Iniciando treinamento do modelo SAR...\n",
            "Treinamento concluído. Salvando o modelo...\n",
            "Modelo salvo em: ../data/sar/movielens_sar_model_time_decay_coefficient_30_similarity_type_SimilarityType.LIFT_top_k_10.model\n",
            "Modelo SAR treinado e salvo com sucesso.\n",
            "Gerando recomendações (removendo itens já vistos)...\n",
            "Juntando títulos dos itens às recomendações...\n",
            "Processo de predição concluído.\n",
            "Calculando métricas de avaliação (ranking)...\n",
            "Avaliação concluída.\n",
            "Resultado para similaridade lift:\n",
            "        MAP   nDCG@K  Precision@K  Recall@K  \\\n",
            "0  0.000098  0.00036     0.000414  0.000183   \n",
            "\n",
            "                                             version algorithm  \n",
            "0  similarity_lift_top_k_10_validate_size_0.25_ti...       sar  \n",
            "\n",
            "Testando similaridade: mutual information\n",
            "Inicializando SarModel...\n",
            "Carregando e preparando os dados...\n",
            "/content/datasets\n",
            "ML_1M\n",
            "/content/datasets\n",
            "ML_1M\n",
            "Dados carregados: 1000209 linhas.\n",
            "Dividindo os dados em treino e teste com python_stratified_split...\n",
            "Conjunto de treino: 750121 linhas, Conjunto de teste: 250088 linhas.\n",
            "Iniciando o processo de avaliação do modelo SAR...\n",
            "Iniciando o processo de predição com o modelo SAR...\n",
            "Iniciando treinamento do modelo SAR...\n",
            "Treinamento concluído. Salvando o modelo...\n",
            "Modelo salvo em: ../data/sar/movielens_sar_model_time_decay_coefficient_30_similarity_type_SimilarityType.MUTUAL_INFORMATION_top_k_10.model\n",
            "Modelo SAR treinado e salvo com sucesso.\n",
            "Gerando recomendações (removendo itens já vistos)...\n",
            "Juntando títulos dos itens às recomendações...\n",
            "Processo de predição concluído.\n",
            "Calculando métricas de avaliação (ranking)...\n",
            "Avaliação concluída.\n",
            "Resultado para similaridade mutual information:\n",
            "       MAP   nDCG@K  Precision@K  Recall@K  \\\n",
            "0  0.00806  0.01879     0.019472  0.003072   \n",
            "\n",
            "                                             version algorithm  \n",
            "0  similarity_mutual information_top_k_10_validat...       sar  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_results = pd.concat([full_results, sar_results], ignore_index=True)\n",
        "full_results.to_csv('01_sar.csv', index=False)"
      ],
      "metadata": {
        "id": "XthPbpk3c15N"
      },
      "id": "XthPbpk3c15N",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_results.head(100)"
      ],
      "metadata": {
        "id": "FpSyzduzxedo",
        "outputId": "daef0de9-3d5f-4478-f217-bc1e06b0124e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "id": "FpSyzduzxedo",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        MAP    nDCG@K  Precision@K  Recall@K  \\\n",
              "0  0.173259  0.281954     0.252086  0.082533   \n",
              "1  0.219533  0.345610     0.307864  0.114765   \n",
              "2  0.006920  0.020386     0.025563  0.005893   \n",
              "3  0.185099  0.309862     0.279222  0.109562   \n",
              "4  0.000000  0.000000     0.000000  0.000000   \n",
              "5  0.000098  0.000360     0.000414  0.000183   \n",
              "6  0.008060  0.018790     0.019472  0.003072   \n",
              "\n",
              "                                             version algorithm  \n",
              "0  similarity_cooccurrence_top_k_10_validate_size...       sar  \n",
              "1  similarity_cosine_top_k_10_validate_size_0.25_...       sar  \n",
              "2  similarity_inclusion index_top_k_10_validate_s...       sar  \n",
              "3  similarity_jaccard_top_k_10_validate_size_0.25...       sar  \n",
              "4  similarity_lexicographers mutual information_t...       sar  \n",
              "5  similarity_lift_top_k_10_validate_size_0.25_ti...       sar  \n",
              "6  similarity_mutual information_top_k_10_validat...       sar  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c0370dfc-a972-45f9-927c-19dd79189bdb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MAP</th>\n",
              "      <th>nDCG@K</th>\n",
              "      <th>Precision@K</th>\n",
              "      <th>Recall@K</th>\n",
              "      <th>version</th>\n",
              "      <th>algorithm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.173259</td>\n",
              "      <td>0.281954</td>\n",
              "      <td>0.252086</td>\n",
              "      <td>0.082533</td>\n",
              "      <td>similarity_cooccurrence_top_k_10_validate_size...</td>\n",
              "      <td>sar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.219533</td>\n",
              "      <td>0.345610</td>\n",
              "      <td>0.307864</td>\n",
              "      <td>0.114765</td>\n",
              "      <td>similarity_cosine_top_k_10_validate_size_0.25_...</td>\n",
              "      <td>sar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.006920</td>\n",
              "      <td>0.020386</td>\n",
              "      <td>0.025563</td>\n",
              "      <td>0.005893</td>\n",
              "      <td>similarity_inclusion index_top_k_10_validate_s...</td>\n",
              "      <td>sar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.185099</td>\n",
              "      <td>0.309862</td>\n",
              "      <td>0.279222</td>\n",
              "      <td>0.109562</td>\n",
              "      <td>similarity_jaccard_top_k_10_validate_size_0.25...</td>\n",
              "      <td>sar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>similarity_lexicographers mutual information_t...</td>\n",
              "      <td>sar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.000098</td>\n",
              "      <td>0.000360</td>\n",
              "      <td>0.000414</td>\n",
              "      <td>0.000183</td>\n",
              "      <td>similarity_lift_top_k_10_validate_size_0.25_ti...</td>\n",
              "      <td>sar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.008060</td>\n",
              "      <td>0.018790</td>\n",
              "      <td>0.019472</td>\n",
              "      <td>0.003072</td>\n",
              "      <td>similarity_mutual information_top_k_10_validat...</td>\n",
              "      <td>sar</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c0370dfc-a972-45f9-927c-19dd79189bdb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c0370dfc-a972-45f9-927c-19dd79189bdb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c0370dfc-a972-45f9-927c-19dd79189bdb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-86eb3b35-13e4-473f-afa1-d3b0a81ea631\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-86eb3b35-13e4-473f-afa1-d3b0a81ea631')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-86eb3b35-13e4-473f-afa1-d3b0a81ea631 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "full_results",
              "summary": "{\n  \"name\": \"full_results\",\n  \"rows\": 7,\n  \"fields\": [\n    {\n      \"column\": \"MAP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10194552951340158,\n        \"min\": 0.0,\n        \"max\": 0.21953313826297013,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.17325853552114984,\n          0.21953313826297013,\n          9.828678988151552e-05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nDCG@K\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1629809462114817,\n        \"min\": 0.0,\n        \"max\": 0.3456095926277089,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.28195402961447125,\n          0.3456095926277089,\n          0.0003599697956260277\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision@K\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1446443617971408,\n        \"min\": 0.0,\n        \"max\": 0.307864238410596,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.2520860927152318,\n          0.307864238410596,\n          0.000413907284768212\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall@K\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0544134143439455,\n        \"min\": 0.0,\n        \"max\": 0.11476521785294554,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.0825326666599016,\n          0.11476521785294554,\n          0.00018298183221023885\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"version\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"similarity_cooccurrence_top_k_10_validate_size_0.25_time_decay_coefficient_30\",\n          \"similarity_cosine_top_k_10_validate_size_0.25_time_decay_coefficient_30\",\n          \"similarity_lift_top_k_10_validate_size_0.25_time_decay_coefficient_30\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"algorithm\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"sar\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import pandas as pd\n",
        "from src.utils.enums import MovieLensDataset\n",
        "from src.ncf_model import NcfModel\n",
        "\n",
        "def evaluate_ncf():\n",
        "    # Parâmetros a serem testados\n",
        "    n_factors_options = [4]\n",
        "    batch_size_options = [256, 512]\n",
        "    lr_options = [1e-3]\n",
        "    epochs_options = [10, 15]\n",
        "\n",
        "    # Parâmetros fixos\n",
        "    layer_sizes = [16, 8, 4]\n",
        "    top_k = 10\n",
        "    test_size = 0.25\n",
        "    seed = 42\n",
        "    dataset = MovieLensDataset.ML_1M\n",
        "\n",
        "    # Cria um DataFrame vazio para armazenar os resultados\n",
        "    df_results = pd.DataFrame()\n",
        "\n",
        "    # Itera por todas as combinações de parâmetros\n",
        "    for n_factors, batch_size, lr, epochs in itertools.product(\n",
        "        n_factors_options, batch_size_options, lr_options, epochs_options\n",
        "    ):\n",
        "        print(f\"\\nTestando: n_factors={n_factors}, batch_size={batch_size}, lr={lr}, epochs={epochs}\")\n",
        "\n",
        "        # Instancia o modelo NCF com a configuração atual\n",
        "        model = NcfModel(\n",
        "            dataset=dataset,\n",
        "            n_factors=n_factors,\n",
        "            batch_size=batch_size,\n",
        "            lr=lr,\n",
        "            layer_sizes=layer_sizes,\n",
        "            epochs=epochs,\n",
        "            top_k=top_k,\n",
        "            test_size=test_size,\n",
        "            seed=seed\n",
        "        )\n",
        "\n",
        "        # Avalia o modelo\n",
        "        result = model.evaluate()\n",
        "\n",
        "        # Adiciona informações de identificação\n",
        "        result['algorithm'] = 'ncf'\n",
        "        result['version'] = f\"n_factors_{n_factors}_batch_size_{batch_size}_lr_{lr}_epochs_{epochs}\"\n",
        "\n",
        "        df_results = pd.concat([df_results, result], ignore_index=True)\n",
        "\n",
        "        print(f\"Resultado: {result}\")\n",
        "\n",
        "    return df_results"
      ],
      "metadata": {
        "id": "YxsLihPdpeCk"
      },
      "id": "YxsLihPdpeCk",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from src.utils.utils import get_torch_device\n",
        "print(get_torch_device())"
      ],
      "metadata": {
        "id": "skUP2tqFRSCa",
        "outputId": "2a681ae5-499c-4f5b-aee2-80e91c0713cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "skUP2tqFRSCa",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.1+cu117\n",
            "11.7\n",
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"numpy\")\n",
        "\n",
        "ncf_result = evaluate_ncf()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhQkGyPRuAGH",
        "outputId": "aee774b4-c4c2-40aa-f948-f076e17d0be3"
      },
      "id": "YhQkGyPRuAGH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testando: n_factors=4, batch_size=256, lr=0.001, epochs=10\n",
            "Inicializando o modelo NcfModel...\n",
            "Preparando os dados com prepare_data_pandas...\n",
            "/content/datasets\n",
            "ML_1M\n",
            "/content/datasets\n",
            "ML_1M\n",
            "Dividindo os dados com python_chrono_split...\n",
            "Conjunto de treino: 750121 linhas, Conjunto de teste: 250088 linhas\n",
            "Filtragem dos dados concluída: o conjunto de teste contém apenas usuários e itens presentes no treino.\n",
            "Iniciando o processo de avaliação...\n",
            "Iniciando o processo de predição...\n",
            "Iniciando o treinamento do modelo...\n",
            "Salvando arquivos temporários para os conjuntos de treino e teste...\n",
            "Construindo o dataset NCF...\n",
            "Construindo o modelo NCF...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1697: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  warnings.warn('`layer.apply` is deprecated and '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_results = pd.concat([full_results, ncf_result], ignore_index=True)\n",
        "full_results.to_csv('02_sar_ncf.csv', index=False)"
      ],
      "metadata": {
        "id": "6A408Ba9t_H5"
      },
      "id": "6A408Ba9t_H5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_results.head(100)"
      ],
      "metadata": {
        "id": "YC9Fe1foxnX7"
      },
      "id": "YC9Fe1foxnX7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import pandas as pd\n",
        "from src.utils.enums import MovieLensDataset\n",
        "from src.bivae_model import BivaeModel\n",
        "\n",
        "def evaluate_bivae():\n",
        "    # Parâmetros a serem testados\n",
        "    latent_dim_options = [50, 100]\n",
        "    epochs_options = [300, 500]\n",
        "    lr_options = [0.001]\n",
        "\n",
        "    # Parâmetros fixos\n",
        "    top_k = 10\n",
        "    batch_size = 1024\n",
        "    encoder_dims = [100]\n",
        "    act_func = 'tanh'\n",
        "    likelihood = 'pois'\n",
        "    test_size = 0.25\n",
        "    seed = 42\n",
        "    dataset = MovieLensDataset.ML_1M\n",
        "\n",
        "    # Cria um DataFrame vazio para armazenar os resultados\n",
        "    df_results = pd.DataFrame()\n",
        "\n",
        "    # Itera por todas as combinações de parâmetros\n",
        "    for latent_dim, epochs, lr in itertools.product(\n",
        "        latent_dim_options, epochs_options, lr_options\n",
        "    ):\n",
        "        print(f\"\\nTestando: latent_dim={latent_dim}, epochs={epochs}, lr={lr}\")\n",
        "\n",
        "        # Instancia o modelo BivaeModel com a configuração atual\n",
        "        model = BivaeModel(\n",
        "            dataset=dataset,\n",
        "            top_k=top_k,\n",
        "            batch_size=batch_size,\n",
        "            latent_dim=latent_dim,\n",
        "            encoder_dims=encoder_dims,\n",
        "            act_func=act_func,\n",
        "            likelihood=likelihood,\n",
        "            epochs=epochs,\n",
        "            lr=lr,\n",
        "            test_size=test_size,\n",
        "            seed=seed\n",
        "        )\n",
        "\n",
        "        # Avalia o modelo\n",
        "        result = model.evaluate()\n",
        "\n",
        "        # Adiciona informações de identificação\n",
        "        result['algorithm'] = 'bivae'\n",
        "        result['version'] = f\"latent_dim_{latent_dim}_epochs_{epochs}_lr_{lr}\"\n",
        "\n",
        "        # Converte o dicionário de resultado em um DataFrame de uma linha e concatena\n",
        "        df_results = pd.concat([df_results, pd.DataFrame([result])], ignore_index=True)\n",
        "\n",
        "        print(f\"Resultado: {result}\")\n",
        "\n",
        "    return df_results\n"
      ],
      "metadata": {
        "id": "VO6C4c6CqQzu"
      },
      "id": "VO6C4c6CqQzu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bivae_result = evaluate_bivae()"
      ],
      "metadata": {
        "id": "lh2QVxKLvogc"
      },
      "id": "lh2QVxKLvogc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_results = pd.concat([full_results, bivae_result], ignore_index=True)\n",
        "full_results.to_csv('03_sar_ncf_bivae.csv', index=False)"
      ],
      "metadata": {
        "id": "OZW50DFtvpAE"
      },
      "id": "OZW50DFtvpAE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_results.head(100)"
      ],
      "metadata": {
        "id": "pXFvw7RTxokF"
      },
      "id": "pXFvw7RTxokF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import pandas as pd\n",
        "from src.utils.enums import MovieLensDataset\n",
        "from src.light_gcn_model import LightGcnModel\n",
        "\n",
        "def evaluate_lightgcn():\n",
        "    # Parâmetros a serem testados\n",
        "    n_layers_options = [2, 3, 4]\n",
        "    lr_options = [0.005, 0.01]\n",
        "    epochs_options = [1, 5]\n",
        "\n",
        "    # Parâmetros fixos\n",
        "    batch_size = 1024\n",
        "    top_k = 10\n",
        "    test_size = 0.2\n",
        "    seed = 42\n",
        "    dataset = MovieLensDataset.ML_1M\n",
        "\n",
        "    # Cria um DataFrame vazio para armazenar os resultados\n",
        "    df_results = pd.DataFrame()\n",
        "\n",
        "    # Itera por todas as combinações de parâmetros\n",
        "    for n_layers, lr, epochs in itertools.product(n_layers_options, lr_options, epochs_options):\n",
        "        print(f\"\\nTestando: n_layers={n_layers}, lr={lr}, epochs={epochs}\")\n",
        "\n",
        "        # Instancia o modelo LightGcnModel com a configuração atual\n",
        "        model = LightGcnModel(\n",
        "            dataset=dataset,\n",
        "            n_layers=n_layers,\n",
        "            batch_size=batch_size,\n",
        "            lr=lr,\n",
        "            epochs=epochs,\n",
        "            top_k=top_k,\n",
        "            test_size=test_size,\n",
        "            seed=seed\n",
        "        )\n",
        "\n",
        "        # Avalia o modelo\n",
        "        result = model.evaluate()\n",
        "\n",
        "        # Adiciona informações de identificação\n",
        "        result['algorithm'] = 'lightgcn'\n",
        "        result['version'] = f\"n_layers_{n_layers}_lr_{lr}_epochs_{epochs}\"\n",
        "\n",
        "        # Converte o dicionário de resultado em um DataFrame de uma linha e concatena\n",
        "        df_results = pd.concat([df_results, pd.DataFrame([result])], ignore_index=True)\n",
        "\n",
        "        print(f\"Resultado: {result}\")\n",
        "\n",
        "    return df_results\n"
      ],
      "metadata": {
        "id": "Xih-qDW4qbEx"
      },
      "id": "Xih-qDW4qbEx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lightgcn_result = evaluate_lightgcn()"
      ],
      "metadata": {
        "id": "gN0D_3ahvvJI"
      },
      "id": "gN0D_3ahvvJI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_results = pd.concat([full_results, lightgcn_result], ignore_index=True)\n",
        "full_results.to_csv('04_sar_ncf_bivae_lightgcn.csv', index=False)"
      ],
      "metadata": {
        "id": "0R6MBN0rvu_p"
      },
      "id": "0R6MBN0rvu_p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_results.head(100)"
      ],
      "metadata": {
        "id": "Syn6qJAYxpl7"
      },
      "id": "Syn6qJAYxpl7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import pandas as pd\n",
        "from src.utils.enums import MovieLensDataset\n",
        "from src.fastai_model import FastAiModel\n",
        "\n",
        "def evaluate_fastai():\n",
        "    # Parâmetros a serem testados\n",
        "    n_factors_options = [40, 50]\n",
        "    epochs_options = [1, 2]\n",
        "\n",
        "    # Parâmetros fixos\n",
        "    test_size = 0.25\n",
        "    top_k = 10\n",
        "    seed = 42\n",
        "    dataset = MovieLensDataset.ML_1M\n",
        "\n",
        "    # Cria um DataFrame vazio para armazenar os resultados\n",
        "    df_results = pd.DataFrame()\n",
        "\n",
        "    # Itera por todas as combinações de parâmetros\n",
        "    for n_factors, epochs in itertools.product(n_factors_options, epochs_options):\n",
        "        print(f\"\\nTestando: n_factors={n_factors}, epochs={epochs}\")\n",
        "\n",
        "        # Instancia o modelo FastAiModel com a configuração atual\n",
        "        model = FastAiModel(\n",
        "            dataset=dataset,\n",
        "            n_factors=n_factors,\n",
        "            test_size=test_size,\n",
        "            epochs=epochs,\n",
        "            top_k=top_k,\n",
        "            seed=seed\n",
        "        )\n",
        "\n",
        "        # Avalia o modelo\n",
        "        result = model.evaluate()\n",
        "\n",
        "        # Adiciona informações de identificação\n",
        "        result['algorithm'] = 'fastai'\n",
        "        result['version'] = f\"n_factors_{n_factors}_epochs_{epochs}\"\n",
        "\n",
        "        # Converte o dicionário de resultado em um DataFrame de uma linha e concatena\n",
        "        df_results = pd.concat([df_results, pd.DataFrame([result])], ignore_index=True)\n",
        "\n",
        "        print(f\"Resultado: {result}\")\n",
        "\n",
        "    return df_results\n"
      ],
      "metadata": {
        "id": "qmaQVlkUqeKn"
      },
      "id": "qmaQVlkUqeKn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fastai_result = evaluate_fastai()"
      ],
      "metadata": {
        "id": "AfhvDeV7vxM3"
      },
      "id": "AfhvDeV7vxM3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_results = pd.concat([full_results, fastai_result], ignore_index=True)\n",
        "full_results.to_csv('05_sar_ncf_bivae_lightgcn_fastai.csv', index=False)"
      ],
      "metadata": {
        "id": "SW91q2BzvxrN"
      },
      "id": "SW91q2BzvxrN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_results.head(100)"
      ],
      "metadata": {
        "id": "JhG3fTv7xqfA"
      },
      "id": "JhG3fTv7xqfA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import pandas as pd\n",
        "from src.utils.enums import MovieLensDataset\n",
        "from src.als_model import SparkAlsModel\n",
        "\n",
        "def evaluate_als(spark):\n",
        "    # Definindo os grids de parâmetros\n",
        "    max_iter_options = [20]\n",
        "    rank_options = [10, 20, 30, 40]\n",
        "    reg_param_options = [0.05]\n",
        "    alpha_options = [0.1]\n",
        "\n",
        "    # Parâmetros fixos\n",
        "    validate_size = 0.25\n",
        "    top_k = 10\n",
        "    seed = 42\n",
        "    dataset = MovieLensDataset.ML_1M\n",
        "\n",
        "    # Cria um DataFrame vazio para armazenar os resultados\n",
        "    df_results = pd.DataFrame()\n",
        "\n",
        "    # Itera por todas as combinações de parâmetros\n",
        "    for max_iter, rank, reg_param, alpha in itertools.product(\n",
        "            max_iter_options, rank_options, reg_param_options, alpha_options\n",
        "    ):\n",
        "        print(f\"\\nTestando: maxIter={max_iter}, rank={rank}, regParam={reg_param}, alpha={alpha}\")\n",
        "\n",
        "        # Instanciando o modelo ALS com a configuração atual\n",
        "        als_model = SparkAlsModel(\n",
        "            spark=spark,\n",
        "            dataset=dataset,\n",
        "            max_iter=max_iter,\n",
        "            rank=rank,\n",
        "            reg_param=reg_param,\n",
        "            alpha=alpha,\n",
        "            validate_size=validate_size,\n",
        "            top_k=top_k,\n",
        "            seed=seed\n",
        "        )\n",
        "\n",
        "\n",
        "        # Avaliando o modelo\n",
        "        result = als_model.evaluate()\n",
        "\n",
        "        # Adiciona as informações desejadas\n",
        "        result['algorithm'] = 'als'\n",
        "        result['version'] = f\"max_iter_{max_iter}_rank_{rank}_reg_param_{reg_param}_alpha_{alpha}\"\n",
        "\n",
        "        df_results = pd.concat([df_results, result], ignore_index=True)\n",
        "        print(f\"Resultado: {result}\")\n",
        "\n",
        "\n",
        "    return df_results"
      ],
      "metadata": {
        "id": "BJzHwNDr2MuB"
      },
      "id": "BJzHwNDr2MuB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from src.utils.spark_session_utils import create_spark_session\n",
        "\n",
        "spark = create_spark_session(\"ALS\")\n",
        "als_result = evaluate_als(spark)"
      ],
      "metadata": {
        "id": "q3VxROhJ2QRu"
      },
      "id": "q3VxROhJ2QRu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_results = pd.concat([full_results, als_result], ignore_index=True)\n",
        "full_results.to_csv('06_sar_ncf_bivae_lightgcn_fastai_als.csv', index=False)"
      ],
      "metadata": {
        "id": "CFiDpEfj2cbp"
      },
      "id": "CFiDpEfj2cbp",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}