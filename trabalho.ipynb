{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# Install java\n",
        "!apt install openjdk-21-jdk"
      ],
      "metadata": {
        "collapsed": true,
        "id": "mE1noAqF9PdU"
      },
      "id": "mE1noAqF9PdU",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!wget \"https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/3.3.4/hadoop-aws-3.3.4.jar\" -P \"spark/lib-jars/\"\n",
        "!wget \"https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.12.699/aws-java-sdk-bundle-1.12.699.jar\" -P \"spark/lib-jars/\"\n",
        "!wget \"https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk/1.12.699/aws-java-sdk-1.12.699.jar\" -P \"spark/lib-jars/\"\n",
        "!wget \"https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-core/1.12.699/aws-java-sdk-core-1.12.699.jar\" -P \"spark/lib-jars/\"\n",
        "!wget \"https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-s3/1.12.699/aws-java-sdk-s3-1.12.699.jar\" -P \"spark/lib-jars/\""
      ],
      "metadata": {
        "collapsed": true,
        "id": "kxGSoMTz_9Ce"
      },
      "id": "kxGSoMTz_9Ce",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!java --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTK3BZ8ZVfcZ",
        "outputId": "dca98ca2-7ca5-4f7c-f8cf-c8ffeaf403e5"
      },
      "id": "pTK3BZ8ZVfcZ",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "openjdk 21.0.6 2025-01-21\n",
            "OpenJDK Runtime Environment (build 21.0.6+7-Ubuntu-122.04.1)\n",
            "OpenJDK 64-Bit Server VM (build 21.0.6+7-Ubuntu-122.04.1, mixed mode, sharing)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:  # When on Google Colab, clone the repository to download any necessary cache.\n",
        "    import google.colab\n",
        "    repo_path = 'cdd'\n",
        "    !git -C $repo_path pull origin || git clone https://github.com/hygo2025/cdd-projeto-final.git $repo_path\n",
        "except:\n",
        "    repo_path = '.'  # Use the local path if not on Google Colab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elmgBR9pVh0g",
        "outputId": "08ecd4c7-e5e2-4c1c-eb66-86de935c9fd3"
      },
      "id": "elmgBR9pVh0g",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%capture\n",
        "!pip install -r cdd/requirements.txt"
      ],
      "metadata": {
        "id": "mTfu6fnAVkYc"
      },
      "id": "mTfu6fnAVkYc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%capture\n",
        "import pkg_resources\n",
        "!pip install -e $repo_path"
      ],
      "metadata": {
        "id": "GAgHJ4f8VtHP"
      },
      "id": "GAgHJ4f8VtHP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# configurar as variáveis de ambiente\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-21-openjdk-amd64\"\n",
        "\n",
        "os.environ[\"SPARK_DRIVER_EXTRACLASSPATH\"] = \"/content/spark/lib-jars/*\"\n",
        "os.environ[\"SPARK_EXECUTOR_EXTRACLASSPATH\"] = \"/content/spark/lib-jars/*\"\n",
        "os.environ[\"SPARK_SERIALIZER\"] = \"org.apache.spark.serializer.KryoSerializer\"\n",
        "os.environ[\"ENV\"] = \"dev\"\n",
        "os.environ[\"PYTHONUNBUFFERED\"] = \"1\"\n",
        "os.environ[\"SPARK_EXECUTOR_MEMORY\"] = \"18g\"\n",
        "os.environ[\"SPARK_DRIVER_MEMORY\"] = \"18g\"\n",
        "os.environ[\"SPARK_MEMORY_FRACTION\"] = \"0.8\"\n",
        "\n",
        "\n",
        "os.environ[\"DOWNLOAD_FOLDER\"] = \"/content/datasets\""
      ],
      "metadata": {
        "id": "H939YnnX-A3D"
      },
      "id": "H939YnnX-A3D",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "V4DTuR9P--H2"
      },
      "id": "V4DTuR9P--H2",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:  # When on Google Colab, clone the repository to download any necessary cache.\n",
        "    import google.colab\n",
        "    repo_path = 'cdd'\n",
        "    !git -C $repo_path pull origin || git clone https://github.com/hygo2025/cdd-projeto-final.git $repo_path\n",
        "except:\n",
        "    repo_path = '.'  # Use the local path if not on Google Colab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4xGPDpcYBHmU",
        "outputId": "a35c8484-6110-4eb4-ab88-76ffc8248a92"
      },
      "id": "4xGPDpcYBHmU",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "import pkg_resources\n",
        "\n",
        "if repo_path not in sys.path:\n",
        "    sys.path.append(repo_path)"
      ],
      "metadata": {
        "id": "xPE1A11QBnM9"
      },
      "id": "xPE1A11QBnM9",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cdd"
      ],
      "metadata": {
        "id": "n6dYXTkxFlEF"
      },
      "id": "n6dYXTkxFlEF",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "full_results = pd.DataFrame()"
      ],
      "metadata": {
        "id": "oib-FQl_cw0W"
      },
      "id": "oib-FQl_cw0W",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from src.sar_model import SarModel\n",
        "from src.utils.enums import MovieLensDataset, SimilarityType\n",
        "\n",
        "def evaluate_sar():\n",
        "    top_k = 10\n",
        "    validate_size = 0.25\n",
        "    time_decay_coefficient = 30\n",
        "    seed = 42\n",
        "    df_results = pd.DataFrame()\n",
        "\n",
        "\n",
        "    # Iterando sobre todas as similaridades definidas na enumeração\n",
        "    for similarity in SimilarityType:\n",
        "        print(f\"\\nTestando similaridade: {similarity.value}\")\n",
        "\n",
        "        # Instanciando o modelo com a similaridade atual\n",
        "        sar_model = SarModel(\n",
        "            dataset=MovieLensDataset.ML_1M,\n",
        "            top_k=top_k,\n",
        "            validate_size=validate_size,\n",
        "            time_decay_coefficient=time_decay_coefficient,\n",
        "            similarity_type=similarity,\n",
        "            seed=seed\n",
        "        )\n",
        "\n",
        "        # Avaliando o modelo\n",
        "        result = sar_model.evaluate()\n",
        "\n",
        "        result['version'] = f\"similarity_{similarity.value}_top_k_{top_k}_validate_size_{validate_size}_time_decay_coefficient_{time_decay_coefficient}\"\n",
        "        result['algorithm'] = 'sar'\n",
        "\n",
        "        df_results = pd.concat([df_results, result], ignore_index=True)\n",
        "\n",
        "        print(f\"Resultado para similaridade {similarity.value}:\")\n",
        "        print(result)\n",
        "    return df_results\n"
      ],
      "metadata": {
        "id": "H1K9GdD8QYrk"
      },
      "id": "H1K9GdD8QYrk",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sar_results = evaluate_sar()"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "211XIAhvV6jM",
        "outputId": "4e744a0d-fa3e-46f3-c9a2-c2230a0e6991"
      },
      "id": "211XIAhvV6jM",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testando similaridade: cooccurrence\n",
            "Inicializando SarModel...\n",
            "Carregando e preparando os dados...\n",
            "/content/datasets\n",
            "ML_1M\n",
            "Dataset ML_1M não encontrado em /content/datasets/ML_1M. Iniciando download e extração...\n",
            "Iniciando download de: https://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
            "Progresso: 100.00%\n",
            "Download concluído.\n",
            "Descompactando /content/datasets/ml-1m.zip para /content/datasets/ML_1M...\n",
            "Descompactação concluída.\n",
            "/content/datasets\n",
            "ML_1M\n",
            "Dados carregados: 1000209 linhas.\n",
            "Dividindo os dados em treino e teste com python_stratified_split...\n",
            "Conjunto de treino: 750121 linhas, Conjunto de teste: 250088 linhas.\n",
            "Iniciando o processo de avaliação do modelo SAR...\n",
            "Iniciando o processo de predição com o modelo SAR...\n",
            "Iniciando treinamento do modelo SAR...\n",
            "Treinamento concluído. Salvando o modelo...\n",
            "Modelo salvo em: ../data/sar/movielens_sar_model_time_decay_coefficient_30_similarity_type_SimilarityType.COCCURRENCE_top_k_10.model\n",
            "Modelo SAR treinado e salvo com sucesso.\n",
            "Gerando recomendações (removendo itens já vistos)...\n",
            "Juntando títulos dos itens às recomendações...\n",
            "Processo de predição concluído.\n",
            "Calculando métricas de avaliação (ranking)...\n",
            "Avaliação concluída.\n",
            "Resultado para similaridade cooccurrence:\n",
            "        MAP    nDCG@K  Precision@K  Recall@K  \\\n",
            "0  0.173259  0.281954     0.252086  0.082533   \n",
            "\n",
            "                                             version algorithm  \n",
            "0  similarity_cooccurrence_top_k_10_validate_size...       sar  \n",
            "\n",
            "Testando similaridade: cosine\n",
            "Inicializando SarModel...\n",
            "Carregando e preparando os dados...\n",
            "/content/datasets\n",
            "ML_1M\n",
            "/content/datasets\n",
            "ML_1M\n",
            "Dados carregados: 1000209 linhas.\n",
            "Dividindo os dados em treino e teste com python_stratified_split...\n",
            "Conjunto de treino: 750121 linhas, Conjunto de teste: 250088 linhas.\n",
            "Iniciando o processo de avaliação do modelo SAR...\n",
            "Iniciando o processo de predição com o modelo SAR...\n",
            "Iniciando treinamento do modelo SAR...\n",
            "Treinamento concluído. Salvando o modelo...\n",
            "Modelo salvo em: ../data/sar/movielens_sar_model_time_decay_coefficient_30_similarity_type_SimilarityType.COSINE_top_k_10.model\n",
            "Modelo SAR treinado e salvo com sucesso.\n",
            "Gerando recomendações (removendo itens já vistos)...\n",
            "Juntando títulos dos itens às recomendações...\n",
            "Processo de predição concluído.\n",
            "Calculando métricas de avaliação (ranking)...\n",
            "Avaliação concluída.\n",
            "Resultado para similaridade cosine:\n",
            "        MAP   nDCG@K  Precision@K  Recall@K  \\\n",
            "0  0.219533  0.34561     0.307864  0.114765   \n",
            "\n",
            "                                             version algorithm  \n",
            "0  similarity_cosine_top_k_10_validate_size_0.25_...       sar  \n",
            "\n",
            "Testando similaridade: inclusion index\n",
            "Inicializando SarModel...\n",
            "Carregando e preparando os dados...\n",
            "/content/datasets\n",
            "ML_1M\n",
            "/content/datasets\n",
            "ML_1M\n",
            "Dados carregados: 1000209 linhas.\n",
            "Dividindo os dados em treino e teste com python_stratified_split...\n",
            "Conjunto de treino: 750121 linhas, Conjunto de teste: 250088 linhas.\n",
            "Iniciando o processo de avaliação do modelo SAR...\n",
            "Iniciando o processo de predição com o modelo SAR...\n",
            "Iniciando treinamento do modelo SAR...\n",
            "Treinamento concluído. Salvando o modelo...\n",
            "Modelo salvo em: ../data/sar/movielens_sar_model_time_decay_coefficient_30_similarity_type_SimilarityType.INCLUSION_INDEX_top_k_10.model\n",
            "Modelo SAR treinado e salvo com sucesso.\n",
            "Gerando recomendações (removendo itens já vistos)...\n",
            "Juntando títulos dos itens às recomendações...\n",
            "Processo de predição concluído.\n",
            "Calculando métricas de avaliação (ranking)...\n",
            "Avaliação concluída.\n",
            "Resultado para similaridade inclusion index:\n",
            "       MAP    nDCG@K  Precision@K  Recall@K  \\\n",
            "0  0.00692  0.020386     0.025563  0.005893   \n",
            "\n",
            "                                             version algorithm  \n",
            "0  similarity_inclusion index_top_k_10_validate_s...       sar  \n",
            "\n",
            "Testando similaridade: jaccard\n",
            "Inicializando SarModel...\n",
            "Carregando e preparando os dados...\n",
            "/content/datasets\n",
            "ML_1M\n",
            "/content/datasets\n",
            "ML_1M\n",
            "Dados carregados: 1000209 linhas.\n",
            "Dividindo os dados em treino e teste com python_stratified_split...\n",
            "Conjunto de treino: 750121 linhas, Conjunto de teste: 250088 linhas.\n",
            "Iniciando o processo de avaliação do modelo SAR...\n",
            "Iniciando o processo de predição com o modelo SAR...\n",
            "Iniciando treinamento do modelo SAR...\n",
            "Treinamento concluído. Salvando o modelo...\n",
            "Modelo salvo em: ../data/sar/movielens_sar_model_time_decay_coefficient_30_similarity_type_SimilarityType.JACCARD_top_k_10.model\n",
            "Modelo SAR treinado e salvo com sucesso.\n",
            "Gerando recomendações (removendo itens já vistos)...\n",
            "Juntando títulos dos itens às recomendações...\n",
            "Processo de predição concluído.\n",
            "Calculando métricas de avaliação (ranking)...\n",
            "Avaliação concluída.\n",
            "Resultado para similaridade jaccard:\n",
            "        MAP    nDCG@K  Precision@K  Recall@K  \\\n",
            "0  0.185099  0.309862     0.279222  0.109562   \n",
            "\n",
            "                                             version algorithm  \n",
            "0  similarity_jaccard_top_k_10_validate_size_0.25...       sar  \n",
            "\n",
            "Testando similaridade: lexicographers mutual information\n",
            "Inicializando SarModel...\n",
            "Carregando e preparando os dados...\n",
            "/content/datasets\n",
            "ML_1M\n",
            "/content/datasets\n",
            "ML_1M\n",
            "Dados carregados: 1000209 linhas.\n",
            "Dividindo os dados em treino e teste com python_stratified_split...\n",
            "Conjunto de treino: 750121 linhas, Conjunto de teste: 250088 linhas.\n",
            "Iniciando o processo de avaliação do modelo SAR...\n",
            "Iniciando o processo de predição com o modelo SAR...\n",
            "Iniciando treinamento do modelo SAR...\n",
            "Treinamento concluído. Salvando o modelo...\n",
            "Modelo salvo em: ../data/sar/movielens_sar_model_time_decay_coefficient_30_similarity_type_SimilarityType.LEXICOGRAPHERS_MUTUAL_INFORMATION_top_k_10.model\n",
            "Modelo SAR treinado e salvo com sucesso.\n",
            "Gerando recomendações (removendo itens já vistos)...\n",
            "Juntando títulos dos itens às recomendações...\n",
            "Processo de predição concluído.\n",
            "Calculando métricas de avaliação (ranking)...\n",
            "Avaliação concluída.\n",
            "Resultado para similaridade lexicographers mutual information:\n",
            "   MAP  nDCG@K  Precision@K  Recall@K  \\\n",
            "0  0.0     0.0          0.0       0.0   \n",
            "\n",
            "                                             version algorithm  \n",
            "0  similarity_lexicographers mutual information_t...       sar  \n",
            "\n",
            "Testando similaridade: lift\n",
            "Inicializando SarModel...\n",
            "Carregando e preparando os dados...\n",
            "/content/datasets\n",
            "ML_1M\n",
            "/content/datasets\n",
            "ML_1M\n",
            "Dados carregados: 1000209 linhas.\n",
            "Dividindo os dados em treino e teste com python_stratified_split...\n",
            "Conjunto de treino: 750121 linhas, Conjunto de teste: 250088 linhas.\n",
            "Iniciando o processo de avaliação do modelo SAR...\n",
            "Iniciando o processo de predição com o modelo SAR...\n",
            "Iniciando treinamento do modelo SAR...\n",
            "Treinamento concluído. Salvando o modelo...\n",
            "Modelo salvo em: ../data/sar/movielens_sar_model_time_decay_coefficient_30_similarity_type_SimilarityType.LIFT_top_k_10.model\n",
            "Modelo SAR treinado e salvo com sucesso.\n",
            "Gerando recomendações (removendo itens já vistos)...\n",
            "Juntando títulos dos itens às recomendações...\n",
            "Processo de predição concluído.\n",
            "Calculando métricas de avaliação (ranking)...\n",
            "Avaliação concluída.\n",
            "Resultado para similaridade lift:\n",
            "        MAP   nDCG@K  Precision@K  Recall@K  \\\n",
            "0  0.000098  0.00036     0.000414  0.000183   \n",
            "\n",
            "                                             version algorithm  \n",
            "0  similarity_lift_top_k_10_validate_size_0.25_ti...       sar  \n",
            "\n",
            "Testando similaridade: mutual information\n",
            "Inicializando SarModel...\n",
            "Carregando e preparando os dados...\n",
            "/content/datasets\n",
            "ML_1M\n",
            "/content/datasets\n",
            "ML_1M\n",
            "Dados carregados: 1000209 linhas.\n",
            "Dividindo os dados em treino e teste com python_stratified_split...\n",
            "Conjunto de treino: 750121 linhas, Conjunto de teste: 250088 linhas.\n",
            "Iniciando o processo de avaliação do modelo SAR...\n",
            "Iniciando o processo de predição com o modelo SAR...\n",
            "Iniciando treinamento do modelo SAR...\n",
            "Treinamento concluído. Salvando o modelo...\n",
            "Modelo salvo em: ../data/sar/movielens_sar_model_time_decay_coefficient_30_similarity_type_SimilarityType.MUTUAL_INFORMATION_top_k_10.model\n",
            "Modelo SAR treinado e salvo com sucesso.\n",
            "Gerando recomendações (removendo itens já vistos)...\n",
            "Juntando títulos dos itens às recomendações...\n",
            "Processo de predição concluído.\n",
            "Calculando métricas de avaliação (ranking)...\n",
            "Avaliação concluída.\n",
            "Resultado para similaridade mutual information:\n",
            "       MAP   nDCG@K  Precision@K  Recall@K  \\\n",
            "0  0.00806  0.01879     0.019472  0.003072   \n",
            "\n",
            "                                             version algorithm  \n",
            "0  similarity_mutual information_top_k_10_validat...       sar  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_results = pd.concat([full_results, sar_results], ignore_index=True)\n",
        "full_results.to_csv('01_sar.csv', index=False)"
      ],
      "metadata": {
        "id": "XthPbpk3c15N"
      },
      "id": "XthPbpk3c15N",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_results.head(100)"
      ],
      "metadata": {
        "id": "FpSyzduzxedo",
        "outputId": "38f6386e-9c20-4db4-9419-573ac887a87d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "id": "FpSyzduzxedo",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        MAP    nDCG@K  Precision@K  Recall@K  \\\n",
              "0  0.173259  0.281954     0.252086  0.082533   \n",
              "1  0.219533  0.345610     0.307864  0.114765   \n",
              "2  0.006920  0.020386     0.025563  0.005893   \n",
              "3  0.185099  0.309862     0.279222  0.109562   \n",
              "4  0.000000  0.000000     0.000000  0.000000   \n",
              "5  0.000098  0.000360     0.000414  0.000183   \n",
              "6  0.008060  0.018790     0.019472  0.003072   \n",
              "\n",
              "                                             version algorithm  \n",
              "0  similarity_cooccurrence_top_k_10_validate_size...       sar  \n",
              "1  similarity_cosine_top_k_10_validate_size_0.25_...       sar  \n",
              "2  similarity_inclusion index_top_k_10_validate_s...       sar  \n",
              "3  similarity_jaccard_top_k_10_validate_size_0.25...       sar  \n",
              "4  similarity_lexicographers mutual information_t...       sar  \n",
              "5  similarity_lift_top_k_10_validate_size_0.25_ti...       sar  \n",
              "6  similarity_mutual information_top_k_10_validat...       sar  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-76085a8b-732d-4c35-a589-bb69668a7183\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MAP</th>\n",
              "      <th>nDCG@K</th>\n",
              "      <th>Precision@K</th>\n",
              "      <th>Recall@K</th>\n",
              "      <th>version</th>\n",
              "      <th>algorithm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.173259</td>\n",
              "      <td>0.281954</td>\n",
              "      <td>0.252086</td>\n",
              "      <td>0.082533</td>\n",
              "      <td>similarity_cooccurrence_top_k_10_validate_size...</td>\n",
              "      <td>sar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.219533</td>\n",
              "      <td>0.345610</td>\n",
              "      <td>0.307864</td>\n",
              "      <td>0.114765</td>\n",
              "      <td>similarity_cosine_top_k_10_validate_size_0.25_...</td>\n",
              "      <td>sar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.006920</td>\n",
              "      <td>0.020386</td>\n",
              "      <td>0.025563</td>\n",
              "      <td>0.005893</td>\n",
              "      <td>similarity_inclusion index_top_k_10_validate_s...</td>\n",
              "      <td>sar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.185099</td>\n",
              "      <td>0.309862</td>\n",
              "      <td>0.279222</td>\n",
              "      <td>0.109562</td>\n",
              "      <td>similarity_jaccard_top_k_10_validate_size_0.25...</td>\n",
              "      <td>sar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>similarity_lexicographers mutual information_t...</td>\n",
              "      <td>sar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.000098</td>\n",
              "      <td>0.000360</td>\n",
              "      <td>0.000414</td>\n",
              "      <td>0.000183</td>\n",
              "      <td>similarity_lift_top_k_10_validate_size_0.25_ti...</td>\n",
              "      <td>sar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.008060</td>\n",
              "      <td>0.018790</td>\n",
              "      <td>0.019472</td>\n",
              "      <td>0.003072</td>\n",
              "      <td>similarity_mutual information_top_k_10_validat...</td>\n",
              "      <td>sar</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-76085a8b-732d-4c35-a589-bb69668a7183')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-76085a8b-732d-4c35-a589-bb69668a7183 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-76085a8b-732d-4c35-a589-bb69668a7183');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2d5d4bb2-113b-4a67-aa2c-70825e044d25\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2d5d4bb2-113b-4a67-aa2c-70825e044d25')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2d5d4bb2-113b-4a67-aa2c-70825e044d25 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "full_results",
              "summary": "{\n  \"name\": \"full_results\",\n  \"rows\": 7,\n  \"fields\": [\n    {\n      \"column\": \"MAP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10194552951340158,\n        \"min\": 0.0,\n        \"max\": 0.21953313826297013,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.17325853552114984,\n          0.21953313826297013,\n          9.828678988151552e-05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nDCG@K\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1629809462114817,\n        \"min\": 0.0,\n        \"max\": 0.3456095926277089,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.28195402961447125,\n          0.3456095926277089,\n          0.0003599697956260277\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision@K\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1446443617971408,\n        \"min\": 0.0,\n        \"max\": 0.307864238410596,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.2520860927152318,\n          0.307864238410596,\n          0.000413907284768212\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall@K\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0544134143439455,\n        \"min\": 0.0,\n        \"max\": 0.11476521785294554,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.0825326666599016,\n          0.11476521785294554,\n          0.00018298183221023885\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"version\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"similarity_cooccurrence_top_k_10_validate_size_0.25_time_decay_coefficient_30\",\n          \"similarity_cosine_top_k_10_validate_size_0.25_time_decay_coefficient_30\",\n          \"similarity_lift_top_k_10_validate_size_0.25_time_decay_coefficient_30\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"algorithm\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"sar\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BjUzjxEKZAKE"
      },
      "id": "BjUzjxEKZAKE",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HX3T0HZwcNDJ"
      },
      "id": "HX3T0HZwcNDJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tTfNcFiBvYKo"
      },
      "id": "tTfNcFiBvYKo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_results.head(100)"
      ],
      "metadata": {
        "id": "BE1Pdwlbxlg8"
      },
      "id": "BE1Pdwlbxlg8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import pandas as pd\n",
        "from src.utils.enums import MovieLensDataset\n",
        "from src.ncf_model import NcfModel\n",
        "\n",
        "def evaluate_ncf():\n",
        "    # Parâmetros a serem testados\n",
        "    n_factors_options = [4]\n",
        "    batch_size_options = [256, 512]\n",
        "    lr_options = [1e-3]\n",
        "    epochs_options = [10, 15]\n",
        "\n",
        "    # Parâmetros fixos\n",
        "    layer_sizes = [16, 8, 4]\n",
        "    top_k = 10\n",
        "    test_size = 0.25\n",
        "    seed = 42\n",
        "    dataset = MovieLensDataset.ML_1M\n",
        "\n",
        "    # Cria um DataFrame vazio para armazenar os resultados\n",
        "    df_results = pd.DataFrame()\n",
        "\n",
        "    # Itera por todas as combinações de parâmetros\n",
        "    for n_factors, batch_size, lr, epochs in itertools.product(\n",
        "        n_factors_options, batch_size_options, lr_options, epochs_options\n",
        "    ):\n",
        "        print(f\"\\nTestando: n_factors={n_factors}, batch_size={batch_size}, lr={lr}, epochs={epochs}\")\n",
        "\n",
        "        # Instancia o modelo NCF com a configuração atual\n",
        "        model = NcfModel(\n",
        "            dataset=dataset,\n",
        "            n_factors=n_factors,\n",
        "            batch_size=batch_size,\n",
        "            lr=lr,\n",
        "            layer_sizes=layer_sizes,\n",
        "            epochs=epochs,\n",
        "            top_k=top_k,\n",
        "            test_size=test_size,\n",
        "            seed=seed\n",
        "        )\n",
        "\n",
        "        # Avalia o modelo\n",
        "        result = model.evaluate()\n",
        "\n",
        "        # Adiciona informações de identificação\n",
        "        result['algorithm'] = 'ncf'\n",
        "        result['version'] = f\"n_factors_{n_factors}_batch_size_{batch_size}_lr_{lr}_epochs_{epochs}\"\n",
        "\n",
        "        df_results = pd.concat([df_results, result], ignore_index=True)\n",
        "\n",
        "        print(f\"Resultado: {result}\")\n",
        "\n",
        "    return df_results"
      ],
      "metadata": {
        "id": "YxsLihPdpeCk"
      },
      "id": "YxsLihPdpeCk",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "# tf.get_logger().setLevel('INFO')\n",
        "\n",
        "ncf_result = evaluate_ncf()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 688
        },
        "id": "YhQkGyPRuAGH",
        "outputId": "e9711333-00a4-4c40-cece-df78a77997d8"
      },
      "id": "YhQkGyPRuAGH",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testando: n_factors=4, batch_size=256, lr=0.001, epochs=10\n",
            "Inicializando o modelo NcfModel...\n",
            "Preparando os dados com prepare_data_pandas...\n",
            "/content/datasets\n",
            "ML_1M\n",
            "/content/datasets\n",
            "ML_1M\n",
            "Dividindo os dados com python_chrono_split...\n",
            "Conjunto de treino: 750121 linhas, Conjunto de teste: 250088 linhas\n",
            "Filtragem dos dados concluída: o conjunto de teste contém apenas usuários e itens presentes no treino.\n",
            "Iniciando o processo de avaliação...\n",
            "Iniciando o processo de predição...\n",
            "Iniciando o treinamento do modelo...\n",
            "Salvando arquivos temporários para os conjuntos de treino e teste...\n",
            "Construindo o dataset NCF...\n",
            "Construindo o modelo NCF...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1697: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  warnings.warn('`layer.apply` is deprecated and '\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-1c0acc2a58b8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# tf.get_logger().setLevel('INFO')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mncf_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_ncf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-8831702fbb14>\u001b[0m in \u001b[0;36mevaluate_ncf\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m# Avalia o modelo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m# Adiciona informações de identificação\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/cdd/src/ncf_model.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Iniciando o processo de avaliação...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0mpredictions_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Calculando métricas de avaliação (top K)...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mmetrics_at_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat_k_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredictions_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/cdd/src/ncf_model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Iniciando o processo de predição...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0musers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/cdd/src/ncf_model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Iniciando o treinamento do modelo...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Treinamento concluído. Salvando o modelo...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/recommenders/models/ncf/ncf_singlenode.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0;31m# get loss and execute optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m                 \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mtrain_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtrain_begin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[1;32m    973\u001b[0m                          run_metadata_ptr)\n\u001b[1;32m    974\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     \u001b[0;31m# or if the call is a partial run that specifies feeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1215\u001b[0;31m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0m\u001b[1;32m   1216\u001b[0m                              feed_dict_tensor, options, run_metadata)\n\u001b[1;32m   1217\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1395\u001b[0;31m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0m\u001b[1;32m   1396\u001b[0m                            run_metadata)\n\u001b[1;32m   1397\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1400\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1403\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1383\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1385\u001b[0;31m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0m\u001b[1;32m   1386\u001b[0m                                       target_list, run_metadata)\n\u001b[1;32m   1387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1476\u001b[0m   def _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list,\n\u001b[1;32m   1477\u001b[0m                           run_metadata):\n\u001b[0;32m-> 1478\u001b[0;31m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0m\u001b[1;32m   1479\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1480\u001b[0m                                             run_metadata)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_results = pd.concat([full_results, ncf_result], ignore_index=True)\n",
        "full_results.to_csv('02_sar_ncf.csv', index=False)"
      ],
      "metadata": {
        "id": "6A408Ba9t_H5"
      },
      "id": "6A408Ba9t_H5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_results.head(100)"
      ],
      "metadata": {
        "id": "YC9Fe1foxnX7"
      },
      "id": "YC9Fe1foxnX7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import pandas as pd\n",
        "from src.utils.enums import MovieLensDataset\n",
        "from src.bivae_model import BivaeModel\n",
        "\n",
        "def evaluate_bivae():\n",
        "    # Parâmetros a serem testados\n",
        "    latent_dim_options = [50, 100]\n",
        "    epochs_options = [300, 500]\n",
        "    lr_options = [0.001]\n",
        "\n",
        "    # Parâmetros fixos\n",
        "    top_k = 10\n",
        "    batch_size = 1024\n",
        "    encoder_dims = [100]\n",
        "    act_func = 'tanh'\n",
        "    likelihood = 'pois'\n",
        "    test_size = 0.25\n",
        "    seed = 42\n",
        "    dataset = MovieLensDataset.ML_1M\n",
        "\n",
        "    # Cria um DataFrame vazio para armazenar os resultados\n",
        "    df_results = pd.DataFrame()\n",
        "\n",
        "    # Itera por todas as combinações de parâmetros\n",
        "    for latent_dim, epochs, lr in itertools.product(\n",
        "        latent_dim_options, epochs_options, lr_options\n",
        "    ):\n",
        "        print(f\"\\nTestando: latent_dim={latent_dim}, epochs={epochs}, lr={lr}\")\n",
        "\n",
        "        # Instancia o modelo BivaeModel com a configuração atual\n",
        "        model = BivaeModel(\n",
        "            dataset=dataset,\n",
        "            top_k=top_k,\n",
        "            batch_size=batch_size,\n",
        "            latent_dim=latent_dim,\n",
        "            encoder_dims=encoder_dims,\n",
        "            act_func=act_func,\n",
        "            likelihood=likelihood,\n",
        "            epochs=epochs,\n",
        "            lr=lr,\n",
        "            test_size=test_size,\n",
        "            seed=seed\n",
        "        )\n",
        "\n",
        "        # Avalia o modelo\n",
        "        result = model.evaluate()\n",
        "\n",
        "        # Adiciona informações de identificação\n",
        "        result['algorithm'] = 'bivae'\n",
        "        result['version'] = f\"latent_dim_{latent_dim}_epochs_{epochs}_lr_{lr}\"\n",
        "\n",
        "        # Converte o dicionário de resultado em um DataFrame de uma linha e concatena\n",
        "        df_results = pd.concat([df_results, pd.DataFrame([result])], ignore_index=True)\n",
        "\n",
        "        print(f\"Resultado: {result}\")\n",
        "\n",
        "    return df_results\n"
      ],
      "metadata": {
        "id": "VO6C4c6CqQzu"
      },
      "id": "VO6C4c6CqQzu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bivae_result = evaluate_bivae()"
      ],
      "metadata": {
        "id": "lh2QVxKLvogc"
      },
      "id": "lh2QVxKLvogc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_results = pd.concat([full_results, bivae_result], ignore_index=True)\n",
        "full_results.to_csv('03_sar_ncf_bivae.csv', index=False)"
      ],
      "metadata": {
        "id": "OZW50DFtvpAE"
      },
      "id": "OZW50DFtvpAE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_results.head(100)"
      ],
      "metadata": {
        "id": "pXFvw7RTxokF"
      },
      "id": "pXFvw7RTxokF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import pandas as pd\n",
        "from src.utils.enums import MovieLensDataset\n",
        "from src.light_gcn_model import LightGcnModel\n",
        "\n",
        "def evaluate_lightgcn():\n",
        "    # Parâmetros a serem testados\n",
        "    n_layers_options = [2, 3, 4]\n",
        "    lr_options = [0.005, 0.01]\n",
        "    epochs_options = [1, 5]\n",
        "\n",
        "    # Parâmetros fixos\n",
        "    batch_size = 1024\n",
        "    top_k = 10\n",
        "    test_size = 0.2\n",
        "    seed = 42\n",
        "    dataset = MovieLensDataset.ML_1M\n",
        "\n",
        "    # Cria um DataFrame vazio para armazenar os resultados\n",
        "    df_results = pd.DataFrame()\n",
        "\n",
        "    # Itera por todas as combinações de parâmetros\n",
        "    for n_layers, lr, epochs in itertools.product(n_layers_options, lr_options, epochs_options):\n",
        "        print(f\"\\nTestando: n_layers={n_layers}, lr={lr}, epochs={epochs}\")\n",
        "\n",
        "        # Instancia o modelo LightGcnModel com a configuração atual\n",
        "        model = LightGcnModel(\n",
        "            dataset=dataset,\n",
        "            n_layers=n_layers,\n",
        "            batch_size=batch_size,\n",
        "            lr=lr,\n",
        "            epochs=epochs,\n",
        "            top_k=top_k,\n",
        "            test_size=test_size,\n",
        "            seed=seed\n",
        "        )\n",
        "\n",
        "        # Avalia o modelo\n",
        "        result = model.evaluate()\n",
        "\n",
        "        # Adiciona informações de identificação\n",
        "        result['algorithm'] = 'lightgcn'\n",
        "        result['version'] = f\"n_layers_{n_layers}_lr_{lr}_epochs_{epochs}\"\n",
        "\n",
        "        # Converte o dicionário de resultado em um DataFrame de uma linha e concatena\n",
        "        df_results = pd.concat([df_results, pd.DataFrame([result])], ignore_index=True)\n",
        "\n",
        "        print(f\"Resultado: {result}\")\n",
        "\n",
        "    return df_results\n"
      ],
      "metadata": {
        "id": "Xih-qDW4qbEx"
      },
      "id": "Xih-qDW4qbEx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lightgcn_result = evaluate_lightgcn()"
      ],
      "metadata": {
        "id": "gN0D_3ahvvJI"
      },
      "id": "gN0D_3ahvvJI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_results = pd.concat([full_results, lightgcn_result], ignore_index=True)\n",
        "full_results.to_csv('04_sar_ncf_bivae_lightgcn.csv', index=False)"
      ],
      "metadata": {
        "id": "0R6MBN0rvu_p"
      },
      "id": "0R6MBN0rvu_p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_results.head(100)"
      ],
      "metadata": {
        "id": "Syn6qJAYxpl7"
      },
      "id": "Syn6qJAYxpl7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import pandas as pd\n",
        "from src.utils.enums import MovieLensDataset\n",
        "from src.fastai_model import FastAiModel\n",
        "\n",
        "def evaluate_fastai():\n",
        "    # Parâmetros a serem testados\n",
        "    n_factors_options = [40, 50]\n",
        "    epochs_options = [1, 2]\n",
        "\n",
        "    # Parâmetros fixos\n",
        "    test_size = 0.25\n",
        "    top_k = 10\n",
        "    seed = 42\n",
        "    dataset = MovieLensDataset.ML_1M\n",
        "\n",
        "    # Cria um DataFrame vazio para armazenar os resultados\n",
        "    df_results = pd.DataFrame()\n",
        "\n",
        "    # Itera por todas as combinações de parâmetros\n",
        "    for n_factors, epochs in itertools.product(n_factors_options, epochs_options):\n",
        "        print(f\"\\nTestando: n_factors={n_factors}, epochs={epochs}\")\n",
        "\n",
        "        # Instancia o modelo FastAiModel com a configuração atual\n",
        "        model = FastAiModel(\n",
        "            dataset=dataset,\n",
        "            n_factors=n_factors,\n",
        "            test_size=test_size,\n",
        "            epochs=epochs,\n",
        "            top_k=top_k,\n",
        "            seed=seed\n",
        "        )\n",
        "\n",
        "        # Avalia o modelo\n",
        "        result = model.evaluate()\n",
        "\n",
        "        # Adiciona informações de identificação\n",
        "        result['algorithm'] = 'fastai'\n",
        "        result['version'] = f\"n_factors_{n_factors}_epochs_{epochs}\"\n",
        "\n",
        "        # Converte o dicionário de resultado em um DataFrame de uma linha e concatena\n",
        "        df_results = pd.concat([df_results, pd.DataFrame([result])], ignore_index=True)\n",
        "\n",
        "        print(f\"Resultado: {result}\")\n",
        "\n",
        "    return df_results\n"
      ],
      "metadata": {
        "id": "qmaQVlkUqeKn"
      },
      "id": "qmaQVlkUqeKn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fastai_result = evaluate_fastai()"
      ],
      "metadata": {
        "id": "AfhvDeV7vxM3"
      },
      "id": "AfhvDeV7vxM3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_results = pd.concat([full_results, fastai_result], ignore_index=True)\n",
        "full_results.to_csv('05_sar_ncf_bivae_lightgcn_fastai.csv', index=False)"
      ],
      "metadata": {
        "id": "SW91q2BzvxrN"
      },
      "id": "SW91q2BzvxrN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_results.head(100)"
      ],
      "metadata": {
        "id": "JhG3fTv7xqfA"
      },
      "id": "JhG3fTv7xqfA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import pandas as pd\n",
        "from src.utils.enums import MovieLensDataset\n",
        "from src.als_model import SparkAlsModel\n",
        "\n",
        "def evaluate_als(spark):\n",
        "    # Definindo os grids de parâmetros\n",
        "    max_iter_options = [20]\n",
        "    rank_options = [10, 20, 30, 40]\n",
        "    reg_param_options = [0.05]\n",
        "    alpha_options = [0.1]\n",
        "\n",
        "    # Parâmetros fixos\n",
        "    validate_size = 0.25\n",
        "    top_k = 10\n",
        "    seed = 42\n",
        "    dataset = MovieLensDataset.ML_1M\n",
        "\n",
        "    # Cria um DataFrame vazio para armazenar os resultados\n",
        "    df_results = pd.DataFrame()\n",
        "\n",
        "    # Itera por todas as combinações de parâmetros\n",
        "    for max_iter, rank, reg_param, alpha in itertools.product(\n",
        "            max_iter_options, rank_options, reg_param_options, alpha_options\n",
        "    ):\n",
        "        print(f\"\\nTestando: maxIter={max_iter}, rank={rank}, regParam={reg_param}, alpha={alpha}\")\n",
        "\n",
        "        # Instanciando o modelo ALS com a configuração atual\n",
        "        als_model = SparkAlsModel(\n",
        "            spark=spark,\n",
        "            dataset=dataset,\n",
        "            max_iter=max_iter,\n",
        "            rank=rank,\n",
        "            reg_param=reg_param,\n",
        "            alpha=alpha,\n",
        "            validate_size=validate_size,\n",
        "            top_k=top_k,\n",
        "            seed=seed\n",
        "        )\n",
        "\n",
        "\n",
        "        # Avaliando o modelo\n",
        "        result = als_model.evaluate()\n",
        "\n",
        "        # Adiciona as informações desejadas\n",
        "        result['algorithm'] = 'als'\n",
        "        result['version'] = f\"max_iter_{max_iter}_rank_{rank}_reg_param_{reg_param}_alpha_{alpha}\"\n",
        "\n",
        "        df_results = pd.concat([df_results, result], ignore_index=True)\n",
        "        print(f\"Resultado: {result}\")\n",
        "\n",
        "\n",
        "    return df_results"
      ],
      "metadata": {
        "id": "BJzHwNDr2MuB"
      },
      "id": "BJzHwNDr2MuB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from src.utils.spark_session_utils import create_spark_session\n",
        "\n",
        "spark = create_spark_session(\"ALS\")\n",
        "als_result = evaluate_als(spark)"
      ],
      "metadata": {
        "id": "q3VxROhJ2QRu"
      },
      "id": "q3VxROhJ2QRu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_results = pd.concat([full_results, als_result], ignore_index=True)\n",
        "full_results.to_csv('06_sar_ncf_bivae_lightgcn_fastai_als.csv', index=False)"
      ],
      "metadata": {
        "id": "CFiDpEfj2cbp"
      },
      "id": "CFiDpEfj2cbp",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}