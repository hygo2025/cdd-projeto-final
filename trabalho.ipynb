{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install java\n",
        "!apt install openjdk-21-jdk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "mE1noAqF9PdU",
        "outputId": "1fc37b55-dd92-4668-d818-cb4a2e377ab4"
      },
      "id": "mE1noAqF9PdU",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "openjdk-21-jdk is already the newest version (21.0.6+7-1~22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget \"https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/3.3.4/hadoop-aws-3.3.4.jar\" -P \"spark/lib-jars/\"\n",
        "!wget \"https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.12.699/aws-java-sdk-bundle-1.12.699.jar\" -P \"spark/lib-jars/\"\n",
        "!wget \"https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk/1.12.699/aws-java-sdk-1.12.699.jar\" -P \"spark/lib-jars/\"\n",
        "!wget \"https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-core/1.12.699/aws-java-sdk-core-1.12.699.jar\" -P \"spark/lib-jars/\"\n",
        "!wget \"https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-s3/1.12.699/aws-java-sdk-s3-1.12.699.jar\" -P \"spark/lib-jars/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kxGSoMTz_9Ce",
        "outputId": "d06d73d0-d0e3-4b72-f5ff-8564ac4d0ab8"
      },
      "id": "kxGSoMTz_9Ce",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-17 01:07:24--  https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/3.3.4/hadoop-aws-3.3.4.jar\n",
            "Resolving repo1.maven.org (repo1.maven.org)... 199.232.192.209, 199.232.196.209, 2a04:4e42:4c::209, ...\n",
            "Connecting to repo1.maven.org (repo1.maven.org)|199.232.192.209|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 962685 (940K) [application/java-archive]\n",
            "Saving to: ‘spark/lib-jars/hadoop-aws-3.3.4.jar.2’\n",
            "\n",
            "hadoop-aws-3.3.4.ja 100%[===================>] 940.12K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2025-03-17 01:07:24 (24.2 MB/s) - ‘spark/lib-jars/hadoop-aws-3.3.4.jar.2’ saved [962685/962685]\n",
            "\n",
            "--2025-03-17 01:07:24--  https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.12.699/aws-java-sdk-bundle-1.12.699.jar\n",
            "Resolving repo1.maven.org (repo1.maven.org)... 199.232.192.209, 199.232.196.209, 2a04:4e42:4c::209, ...\n",
            "Connecting to repo1.maven.org (repo1.maven.org)|199.232.192.209|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 376483545 (359M) [application/java-archive]\n",
            "Saving to: ‘spark/lib-jars/aws-java-sdk-bundle-1.12.699.jar.2’\n",
            "\n",
            "aws-java-sdk-bundle 100%[===================>] 359.04M   178MB/s    in 2.0s    \n",
            "\n",
            "2025-03-17 01:07:26 (178 MB/s) - ‘spark/lib-jars/aws-java-sdk-bundle-1.12.699.jar.2’ saved [376483545/376483545]\n",
            "\n",
            "--2025-03-17 01:07:26--  https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk/1.12.699/aws-java-sdk-1.12.699.jar\n",
            "Resolving repo1.maven.org (repo1.maven.org)... 199.232.192.209, 199.232.196.209, 2a04:4e42:4c::209, ...\n",
            "Connecting to repo1.maven.org (repo1.maven.org)|199.232.192.209|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5339 (5.2K) [application/java-archive]\n",
            "Saving to: ‘spark/lib-jars/aws-java-sdk-1.12.699.jar.2’\n",
            "\n",
            "aws-java-sdk-1.12.6 100%[===================>]   5.21K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-17 01:07:26 (60.0 MB/s) - ‘spark/lib-jars/aws-java-sdk-1.12.699.jar.2’ saved [5339/5339]\n",
            "\n",
            "--2025-03-17 01:07:26--  https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-core/1.12.699/aws-java-sdk-core-1.12.699.jar\n",
            "Resolving repo1.maven.org (repo1.maven.org)... 199.232.192.209, 199.232.196.209, 2a04:4e42:4c::209, ...\n",
            "Connecting to repo1.maven.org (repo1.maven.org)|199.232.192.209|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1038162 (1014K) [application/java-archive]\n",
            "Saving to: ‘spark/lib-jars/aws-java-sdk-core-1.12.699.jar.2’\n",
            "\n",
            "aws-java-sdk-core-1 100%[===================>]   1014K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2025-03-17 01:07:26 (28.5 MB/s) - ‘spark/lib-jars/aws-java-sdk-core-1.12.699.jar.2’ saved [1038162/1038162]\n",
            "\n",
            "--2025-03-17 01:07:26--  https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-s3/1.12.699/aws-java-sdk-s3-1.12.699.jar\n",
            "Resolving repo1.maven.org (repo1.maven.org)... 199.232.192.209, 199.232.196.209, 2a04:4e42:4c::209, ...\n",
            "Connecting to repo1.maven.org (repo1.maven.org)|199.232.192.209|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1272467 (1.2M) [application/java-archive]\n",
            "Saving to: ‘spark/lib-jars/aws-java-sdk-s3-1.12.699.jar.2’\n",
            "\n",
            "aws-java-sdk-s3-1.1 100%[===================>]   1.21M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2025-03-17 01:07:27 (25.6 MB/s) - ‘spark/lib-jars/aws-java-sdk-s3-1.12.699.jar.2’ saved [1272467/1272467]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!java --version"
      ],
      "metadata": {
        "id": "pTK3BZ8ZVfcZ",
        "outputId": "a74a7be5-3e5d-4c1e-8443-40a40fe9521b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "pTK3BZ8ZVfcZ",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "openjdk 21.0.6 2025-01-21\n",
            "OpenJDK Runtime Environment (build 21.0.6+7-Ubuntu-122.04.1)\n",
            "OpenJDK 64-Bit Server VM (build 21.0.6+7-Ubuntu-122.04.1, mixed mode, sharing)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:  # When on Google Colab, clone the repository to download any necessary cache.\n",
        "    import google.colab\n",
        "    repo_path = 'cdd'\n",
        "    !git -C $repo_path pull origin || git clone https://github.com/hygo2025/cdd-projeto-final.git $repo_path\n",
        "except:\n",
        "    repo_path = '.'  # Use the local path if not on Google Colab"
      ],
      "metadata": {
        "id": "elmgBR9pVh0g",
        "outputId": "24f4ba41-18ca-4263-d0b1-83b75b66d6c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "elmgBR9pVh0g",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r cdd/requirements.txt"
      ],
      "metadata": {
        "id": "mTfu6fnAVkYc",
        "outputId": "173eda9c-4e1c-4d52-a03f-6441213c3c10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "mTfu6fnAVkYc",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ignoring spacy: markers 'python_version <= \"3.8\"' don't match your environment\n",
            "Collecting category-encoders<3,>=2.6.0 (from -r cdd/requirements.txt (line 6))\n",
            "  Using cached category_encoders-2.8.1-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting cornac<3,>=2.3.0 (from -r cdd/requirements.txt (line 7))\n",
            "  Using cached cornac-2.3.0-cp311-cp311-manylinux1_x86_64.whl.metadata (37 kB)\n",
            "Requirement already satisfied: hyperopt<1,>=0.2.7 in /usr/local/lib/python3.11/dist-packages (from -r cdd/requirements.txt (line 8)) (0.2.7)\n",
            "Requirement already satisfied: lightgbm<5,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from -r cdd/requirements.txt (line 9)) (4.5.0)\n",
            "Collecting locust<3,>=2.12.2 (from -r cdd/requirements.txt (line 10))\n",
            "  Using cached locust-2.33.2-py3-none-any.whl.metadata (9.6 kB)\n",
            "Collecting memory-profiler<1,>=0.61.0 (from -r cdd/requirements.txt (line 11))\n",
            "  Using cached memory_profiler-0.61.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: nltk<4,>=3.8.1 in /usr/local/lib/python3.11/dist-packages (from -r cdd/requirements.txt (line 12)) (3.9.1)\n",
            "Requirement already satisfied: numba<1,>=0.57.0 in /usr/local/lib/python3.11/dist-packages (from -r cdd/requirements.txt (line 13)) (0.60.0)\n",
            "Requirement already satisfied: pandas<3.0.0,>2.0.0 in /usr/local/lib/python3.11/dist-packages (from -r cdd/requirements.txt (line 14)) (2.2.2)\n",
            "Collecting pandera>=0.15.0 (from pandera[strategies]>=0.15.0->-r cdd/requirements.txt (line 15))\n",
            "  Using cached pandera-0.23.1-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: retrying<2,>=1.3.4 in /usr/local/lib/python3.11/dist-packages (from -r cdd/requirements.txt (line 16)) (1.3.4)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from -r cdd/requirements.txt (line 17)) (1.6.1)\n",
            "Collecting scikit-surprise>=1.1.3 (from -r cdd/requirements.txt (line 18))\n",
            "  Using cached scikit_surprise-1.1.4-cp311-cp311-linux_x86_64.whl\n",
            "Requirement already satisfied: seaborn<1,>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from -r cdd/requirements.txt (line 19)) (0.13.2)\n",
            "Requirement already satisfied: statsmodels>=0.14.4 in /usr/local/lib/python3.11/dist-packages (from -r cdd/requirements.txt (line 20)) (0.14.4)\n",
            "Requirement already satisfied: transformers<5,>=4.27.0 in /usr/local/lib/python3.11/dist-packages (from -r cdd/requirements.txt (line 21)) (4.48.3)\n",
            "Collecting dynaconf (from -r cdd/requirements.txt (line 24))\n",
            "  Using cached dynaconf-3.2.10-py2.py3-none-any.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r cdd/requirements.txt (line 25)) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from -r cdd/requirements.txt (line 26)) (2.32.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from -r cdd/requirements.txt (line 27)) (1.4.2)\n",
            "Requirement already satisfied: fastai==2.7.19 in /usr/local/lib/python3.11/dist-packages (from -r cdd/requirements.txt (line 30)) (2.7.19)\n",
            "Requirement already satisfied: nvidia-ml-py>=11.525.84 in /usr/local/lib/python3.11/dist-packages (from -r cdd/requirements.txt (line 31)) (12.570.86)\n",
            "Collecting tensorflow!=2.10.0.*,!=2.9.0.*,!=2.9.1,!=2.9.2,<2.16,>=2.8.4 (from -r cdd/requirements.txt (line 33))\n",
            "  Using cached tensorflow-2.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: tf-slim>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from -r cdd/requirements.txt (line 34)) (1.1.0)\n",
            "Requirement already satisfied: torch<3,>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from -r cdd/requirements.txt (line 35)) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from -r cdd/requirements.txt (line 36)) (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from -r cdd/requirements.txt (line 37)) (2.6.0+cu124)\n",
            "Requirement already satisfied: pyarrow>=10.0.1 in /usr/local/lib/python3.11/dist-packages (from -r cdd/requirements.txt (line 40)) (18.1.0)\n",
            "Requirement already satisfied: pyspark<4.0.0,>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from -r cdd/requirements.txt (line 41)) (3.5.5)\n",
            "Collecting tensorrt (from -r cdd/requirements.txt (line 48))\n",
            "  Using cached tensorrt-10.9.0.34-py2.py3-none-any.whl\n",
            "Collecting recommenders[gpu] (from -r cdd/requirements.txt (line 44))\n",
            "  Using cached recommenders-1.2.1-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (from fastai==2.7.19->-r cdd/requirements.txt (line 30)) (24.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from fastai==2.7.19->-r cdd/requirements.txt (line 30)) (24.2)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.11/dist-packages (from fastai==2.7.19->-r cdd/requirements.txt (line 30)) (0.0.7)\n",
            "Requirement already satisfied: fastcore<1.8,>=1.5.29 in /usr/local/lib/python3.11/dist-packages (from fastai==2.7.19->-r cdd/requirements.txt (line 30)) (1.7.29)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from fastai==2.7.19->-r cdd/requirements.txt (line 30)) (3.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from fastai==2.7.19->-r cdd/requirements.txt (line 30)) (6.0.2)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.11/dist-packages (from fastai==2.7.19->-r cdd/requirements.txt (line 30)) (1.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from fastai==2.7.19->-r cdd/requirements.txt (line 30)) (11.1.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from fastai==2.7.19->-r cdd/requirements.txt (line 30)) (1.13.1)\n",
            "Requirement already satisfied: spacy<4 in /usr/local/lib/python3.11/dist-packages (from fastai==2.7.19->-r cdd/requirements.txt (line 30)) (3.7.5)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from category-encoders<3,>=2.6.0->-r cdd/requirements.txt (line 6)) (1.26.4)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from category-encoders<3,>=2.6.0->-r cdd/requirements.txt (line 6)) (1.0.1)\n",
            "Collecting powerlaw (from cornac<3,>=2.3.0->-r cdd/requirements.txt (line 7))\n",
            "  Using cached powerlaw-1.5-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from hyperopt<1,>=0.2.7->-r cdd/requirements.txt (line 8)) (1.17.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.11/dist-packages (from hyperopt<1,>=0.2.7->-r cdd/requirements.txt (line 8)) (3.4.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from hyperopt<1,>=0.2.7->-r cdd/requirements.txt (line 8)) (1.0.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from hyperopt<1,>=0.2.7->-r cdd/requirements.txt (line 8)) (3.1.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.11/dist-packages (from hyperopt<1,>=0.2.7->-r cdd/requirements.txt (line 8)) (0.10.9.7)\n",
            "Collecting configargparse>=1.5.5 (from locust<3,>=2.12.2->-r cdd/requirements.txt (line 10))\n",
            "  Using cached ConfigArgParse-1.7-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting flask-cors>=3.0.10 (from locust<3,>=2.12.2->-r cdd/requirements.txt (line 10))\n",
            "  Using cached flask_cors-5.0.1-py3-none-any.whl.metadata (961 bytes)\n",
            "Collecting flask-login>=0.6.3 (from locust<3,>=2.12.2->-r cdd/requirements.txt (line 10))\n",
            "  Using cached Flask_Login-0.6.3-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: flask>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from locust<3,>=2.12.2->-r cdd/requirements.txt (line 10)) (3.1.0)\n",
            "Collecting gevent>=22.10.2 (from locust<3,>=2.12.2->-r cdd/requirements.txt (line 10))\n",
            "  Using cached gevent-24.11.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting geventhttpclient>=2.3.1 (from locust<3,>=2.12.2->-r cdd/requirements.txt (line 10))\n",
            "  Using cached geventhttpclient-2.3.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: msgpack>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from locust<3,>=2.12.2->-r cdd/requirements.txt (line 10)) (1.1.0)\n",
            "Requirement already satisfied: psutil>=5.9.1 in /usr/local/lib/python3.11/dist-packages (from locust<3,>=2.12.2->-r cdd/requirements.txt (line 10)) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=25.0.0 in /usr/local/lib/python3.11/dist-packages (from locust<3,>=2.12.2->-r cdd/requirements.txt (line 10)) (26.3.0)\n",
            "Requirement already satisfied: setuptools>=70.0.0 in /usr/local/lib/python3.11/dist-packages (from locust<3,>=2.12.2->-r cdd/requirements.txt (line 10)) (75.1.0)\n",
            "Requirement already satisfied: werkzeug>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from locust<3,>=2.12.2->-r cdd/requirements.txt (line 10)) (3.1.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk<4,>=3.8.1->-r cdd/requirements.txt (line 12)) (8.1.8)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk<4,>=3.8.1->-r cdd/requirements.txt (line 12)) (2024.11.6)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba<1,>=0.57.0->-r cdd/requirements.txt (line 13)) (0.43.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>2.0.0->-r cdd/requirements.txt (line 14)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>2.0.0->-r cdd/requirements.txt (line 14)) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>2.0.0->-r cdd/requirements.txt (line 14)) (2025.1)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from pandera>=0.15.0->pandera[strategies]>=0.15.0->-r cdd/requirements.txt (line 15)) (2.10.6)\n",
            "Requirement already satisfied: typeguard in /usr/local/lib/python3.11/dist-packages (from pandera>=0.15.0->pandera[strategies]>=0.15.0->-r cdd/requirements.txt (line 15)) (4.4.2)\n",
            "Collecting typing_inspect>=0.6.0 (from pandera>=0.15.0->pandera[strategies]>=0.15.0->-r cdd/requirements.txt (line 15))\n",
            "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2,>=1.2.0->-r cdd/requirements.txt (line 17)) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers<5,>=4.27.0->-r cdd/requirements.txt (line 21)) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers<5,>=4.27.0->-r cdd/requirements.txt (line 21)) (0.28.1)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5,>=4.27.0->-r cdd/requirements.txt (line 21)) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5,>=4.27.0->-r cdd/requirements.txt (line 21)) (0.5.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->-r cdd/requirements.txt (line 26)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->-r cdd/requirements.txt (line 26)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->-r cdd/requirements.txt (line 26)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->-r cdd/requirements.txt (line 26)) (2025.1.31)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow!=2.10.0.*,!=2.9.0.*,!=2.9.1,!=2.9.2,<2.16,>=2.8.4->-r cdd/requirements.txt (line 33)) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow!=2.10.0.*,!=2.9.0.*,!=2.9.1,!=2.9.2,<2.16,>=2.8.4->-r cdd/requirements.txt (line 33)) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.11/dist-packages (from tensorflow!=2.10.0.*,!=2.9.0.*,!=2.9.1,!=2.9.2,<2.16,>=2.8.4->-r cdd/requirements.txt (line 33)) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow!=2.10.0.*,!=2.9.0.*,!=2.9.1,!=2.9.2,<2.16,>=2.8.4->-r cdd/requirements.txt (line 33)) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow!=2.10.0.*,!=2.9.0.*,!=2.9.1,!=2.9.2,<2.16,>=2.8.4->-r cdd/requirements.txt (line 33)) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow!=2.10.0.*,!=2.9.0.*,!=2.9.1,!=2.9.2,<2.16,>=2.8.4->-r cdd/requirements.txt (line 33)) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow!=2.10.0.*,!=2.9.0.*,!=2.9.1,!=2.9.2,<2.16,>=2.8.4->-r cdd/requirements.txt (line 33)) (18.1.1)\n",
            "Collecting ml-dtypes~=0.3.1 (from tensorflow!=2.10.0.*,!=2.9.0.*,!=2.9.1,!=2.9.2,<2.16,>=2.8.4->-r cdd/requirements.txt (line 33))\n",
            "  Using cached ml_dtypes-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow!=2.10.0.*,!=2.9.0.*,!=2.9.1,!=2.9.2,<2.16,>=2.8.4->-r cdd/requirements.txt (line 33)) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow!=2.10.0.*,!=2.9.0.*,!=2.9.1,!=2.9.2,<2.16,>=2.8.4->-r cdd/requirements.txt (line 33)) (4.25.6)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow!=2.10.0.*,!=2.9.0.*,!=2.9.1,!=2.9.2,<2.16,>=2.8.4->-r cdd/requirements.txt (line 33)) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow!=2.10.0.*,!=2.9.0.*,!=2.9.1,!=2.9.2,<2.16,>=2.8.4->-r cdd/requirements.txt (line 33)) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow!=2.10.0.*,!=2.9.0.*,!=2.9.1,!=2.9.2,<2.16,>=2.8.4->-r cdd/requirements.txt (line 33)) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow!=2.10.0.*,!=2.9.0.*,!=2.9.1,!=2.9.2,<2.16,>=2.8.4->-r cdd/requirements.txt (line 33)) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow!=2.10.0.*,!=2.9.0.*,!=2.9.1,!=2.9.2,<2.16,>=2.8.4->-r cdd/requirements.txt (line 33)) (1.71.0)\n",
            "Collecting tensorboard<2.16,>=2.15 (from tensorflow!=2.10.0.*,!=2.9.0.*,!=2.9.1,!=2.9.2,<2.16,>=2.8.4->-r cdd/requirements.txt (line 33))\n",
            "  Using cached tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow!=2.10.0.*,!=2.9.0.*,!=2.9.1,!=2.9.2,<2.16,>=2.8.4->-r cdd/requirements.txt (line 33)) (2.15.0)\n",
            "Collecting keras<2.16,>=2.15.0 (from tensorflow!=2.10.0.*,!=2.9.0.*,!=2.9.1,!=2.9.2,<2.16,>=2.8.4->-r cdd/requirements.txt (line 33))\n",
            "  Using cached keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0.1->-r cdd/requirements.txt (line 35)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0.1->-r cdd/requirements.txt (line 35)) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3,>=2.0.1->-r cdd/requirements.txt (line 35))\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3,>=2.0.1->-r cdd/requirements.txt (line 35))\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3,>=2.0.1->-r cdd/requirements.txt (line 35))\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3,>=2.0.1->-r cdd/requirements.txt (line 35))\n",
            "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3,>=2.0.1->-r cdd/requirements.txt (line 35))\n",
            "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3,>=2.0.1->-r cdd/requirements.txt (line 35))\n",
            "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3,>=2.0.1->-r cdd/requirements.txt (line 35))\n",
            "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3,>=2.0.1->-r cdd/requirements.txt (line 35))\n",
            "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3,>=2.0.1->-r cdd/requirements.txt (line 35))\n",
            "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0.1->-r cdd/requirements.txt (line 35)) (0.6.2)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch<3,>=2.0.1->-r cdd/requirements.txt (line 35))\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0.1->-r cdd/requirements.txt (line 35)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3,>=2.0.1->-r cdd/requirements.txt (line 35))\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0.1->-r cdd/requirements.txt (line 35)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0.1->-r cdd/requirements.txt (line 35)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0.1->-r cdd/requirements.txt (line 35)) (1.3.0)\n",
            "Requirement already satisfied: notebook<8,>=6.5.5 in /usr/local/lib/python3.11/dist-packages (from recommenders[gpu]->-r cdd/requirements.txt (line 44)) (6.5.5)\n",
            "INFO: pip is looking at multiple versions of tensorflow[and-cuda] to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tensorflow[and-cuda] (from -r cdd/requirements.txt (line 47))\n",
            "  Using cached tensorflow-2.15.0.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "  Using cached tensorflow-2.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "  Using cached tensorflow-2.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "  Using cached tensorflow-2.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "  Using cached tensorflow-2.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "\u001b[33mWARNING: tensorflow 2.13.1 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow!=2.10.0.*,!=2.9.0.*,!=2.9.1,!=2.9.2,<2.16,>=2.8.4->-r cdd/requirements.txt (line 33))\n",
            "  Using cached gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting tensorflow[and-cuda] (from -r cdd/requirements.txt (line 47))\n",
            "  Using cached tensorflow-2.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "\u001b[33mWARNING: tensorflow 2.13.0 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0m  Using cached tensorflow-2.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "\u001b[33mWARNING: tensorflow 2.12.1 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]->-r cdd/requirements.txt (line 47)) (0.5.2)\n",
            "INFO: pip is still looking at multiple versions of tensorflow[and-cuda] to determine which version is compatible with other requirements. This could take a while.\n",
            "  Using cached tensorflow-2.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "\u001b[33mWARNING: tensorflow 2.12.0 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting recommenders[gpu] (from -r cdd/requirements.txt (line 44))\n",
            "  Using cached recommenders-1.2.0-py3-none-any.whl.metadata (13 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "\u001b[33mWARNING: tensorflow 2.13.1 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: tensorflow 2.13.0 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: tensorflow 2.12.1 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: tensorflow 2.12.0 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting torchaudio (from -r cdd/requirements.txt (line 37))\n",
            "  Using cached torchaudio-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "\u001b[33mWARNING: tensorflow 2.13.1 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: tensorflow 2.13.0 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: tensorflow 2.12.1 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: tensorflow 2.12.0 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting torchvision (from -r cdd/requirements.txt (line 36))\n",
            "  Using cached torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "\u001b[33mWARNING: tensorflow 2.13.1 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: tensorflow 2.13.0 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: tensorflow 2.12.1 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: tensorflow 2.12.0 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting torch<3,>=2.0.1 (from -r cdd/requirements.txt (line 35))\n",
            "  Using cached torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "\u001b[33mWARNING: tensorflow 2.13.1 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: tensorflow 2.13.0 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: tensorflow 2.12.1 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: tensorflow 2.12.0 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0m  Using cached torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Collecting triton==3.1.0 (from torch<3,>=2.0.1->-r cdd/requirements.txt (line 35))\n",
            "  Using cached triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "\u001b[33mWARNING: tensorflow 2.13.1 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: tensorflow 2.13.0 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: tensorflow 2.12.1 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: tensorflow 2.12.0 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting torch<3,>=2.0.1 (from -r cdd/requirements.txt (line 35))\n",
            "  Using cached torch-2.5.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "\u001b[33mWARNING: tensorflow 2.13.1 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: tensorflow 2.13.0 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: tensorflow 2.12.1 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: tensorflow 2.12.0 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0m  Using cached torch-2.4.1-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<3,>=2.0.1->-r cdd/requirements.txt (line 35))\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<3,>=2.0.1->-r cdd/requirements.txt (line 35))\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<3,>=2.0.1->-r cdd/requirements.txt (line 35))\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch<3,>=2.0.1->-r cdd/requirements.txt (line 35))\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch<3,>=2.0.1->-r cdd/requirements.txt (line 35))\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch<3,>=2.0.1->-r cdd/requirements.txt (line 35))\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch<3,>=2.0.1->-r cdd/requirements.txt (line 35))\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch<3,>=2.0.1->-r cdd/requirements.txt (line 35))\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch<3,>=2.0.1->-r cdd/requirements.txt (line 35))\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch<3,>=2.0.1->-r cdd/requirements.txt (line 35))\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.0.0 (from torch<3,>=2.0.1->-r cdd/requirements.txt (line 35))\n",
            "  Using cached triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<3,>=2.0.1->-r cdd/requirements.txt (line 35)) (12.2.140)\n",
            "\u001b[33mWARNING: tensorflow 2.13.1 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: tensorflow 2.13.0 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: tensorflow 2.12.1 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: tensorflow 2.12.0 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting torch<3,>=2.0.1 (from -r cdd/requirements.txt (line 35))\n",
            "  Using cached torch-2.4.0-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "\u001b[33mWARNING: tensorflow 2.13.1 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: tensorflow 2.13.0 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: tensorflow 2.12.1 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: tensorflow 2.12.0 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0m  Using cached torch-2.3.1-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch<3,>=2.0.1->-r cdd/requirements.txt (line 35))\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting triton==2.3.1 (from torch<3,>=2.0.1->-r cdd/requirements.txt (line 35))\n",
            "  Using cached triton-2.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "\u001b[33mWARNING: tensorflow 2.13.1 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: tensorflow 2.13.0 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: tensorflow 2.12.1 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: tensorflow 2.12.0 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting torch<3,>=2.0.1 (from -r cdd/requirements.txt (line 35))\n",
            "  Using cached torch-2.3.0-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Collecting triton==2.3.0 (from torch<3,>=2.0.1->-r cdd/requirements.txt (line 35))\n",
            "  Using cached triton-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "\u001b[33mWARNING: tensorflow 2.13.1 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: tensorflow 2.13.0 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: tensorflow 2.12.1 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: tensorflow 2.12.0 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting torch<3,>=2.0.1 (from -r cdd/requirements.txt (line 35))\n",
            "  Using cached torch-2.2.2-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch<3,>=2.0.1->-r cdd/requirements.txt (line 35))\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting triton==2.2.0 (from torch<3,>=2.0.1->-r cdd/requirements.txt (line 35))\n",
            "  Using cached triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "\u001b[33mWARNING: tensorflow 2.13.1 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: tensorflow 2.13.0 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: tensorflow 2.12.1 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: tensorflow 2.12.0 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting torch<3,>=2.0.1 (from -r cdd/requirements.txt (line 35))\n",
            "  Using cached torch-2.2.1-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "\u001b[33mWARNING: tensorflow 2.13.1 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: tensorflow 2.13.0 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: tensorflow 2.12.1 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: tensorflow 2.12.0 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0m  Using cached torch-2.2.0-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "\u001b[33mWARNING: tensorflow 2.13.1 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: tensorflow 2.13.0 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: tensorflow 2.12.1 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: tensorflow 2.12.0 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0m  Using cached torch-2.1.2-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Collecting nvidia-nccl-cu12==2.18.1 (from torch<3,>=2.0.1->-r cdd/requirements.txt (line 35))\n",
            "  Using cached nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting triton==2.1.0 (from torch<3,>=2.0.1->-r cdd/requirements.txt (line 35))\n",
            "  Using cached triton-2.1.0-0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "\u001b[33mWARNING: tensorflow 2.13.1 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: tensorflow 2.13.0 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: tensorflow 2.12.1 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: tensorflow 2.12.0 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting torch<3,>=2.0.1 (from -r cdd/requirements.txt (line 35))\n",
            "  Using cached torch-2.1.1-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "\u001b[33mWARNING: tensorflow 2.13.1 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: tensorflow 2.13.0 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: tensorflow 2.12.1 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: tensorflow 2.12.0 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0m  Using cached torch-2.1.0-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "\u001b[33mWARNING: tensorflow 2.13.1 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: tensorflow 2.13.0 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: tensorflow 2.12.1 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: tensorflow 2.12.0 does not provide the extra 'and-cuda'\u001b[0m\u001b[33m\n",
            "\u001b[0m  Using cached torch-2.0.1-cp311-cp311-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0.1->-r cdd/requirements.txt (line 35)) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0.1->-r cdd/requirements.txt (line 35)) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0.1->-r cdd/requirements.txt (line 35)) (11.7.101)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch<3,>=2.0.1->-r cdd/requirements.txt (line 35))\n",
            "  Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch<3,>=2.0.1->-r cdd/requirements.txt (line 35))\n",
            "  Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0.1->-r cdd/requirements.txt (line 35)) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0.1->-r cdd/requirements.txt (line 35)) (10.2.10.91)\n",
            "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch<3,>=2.0.1->-r cdd/requirements.txt (line 35))\n",
            "  Using cached nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0.1->-r cdd/requirements.txt (line 35)) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0.1->-r cdd/requirements.txt (line 35)) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0.1->-r cdd/requirements.txt (line 35)) (11.7.91)\n",
            "Collecting triton==2.0.0 (from torch<3,>=2.0.1->-r cdd/requirements.txt (line 35))\n",
            "  Using cached triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch<3,>=2.0.1->-r cdd/requirements.txt (line 35)) (0.45.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch<3,>=2.0.1->-r cdd/requirements.txt (line 35)) (3.31.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch<3,>=2.0.1->-r cdd/requirements.txt (line 35)) (18.1.8)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.2.5.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]->-r cdd/requirements.txt (line 47)) (12.2.5.6)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.2.142 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]->-r cdd/requirements.txt (line 47)) (12.2.142)\n",
            "Requirement already satisfied: nvidia-cuda-nvcc-cu12==12.2.140 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]->-r cdd/requirements.txt (line 47)) (12.2.140)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.2.140 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]->-r cdd/requirements.txt (line 47)) (12.2.140)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.2.140 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]->-r cdd/requirements.txt (line 47)) (12.2.140)\n",
            "Collecting nvidia-cudnn-cu12==8.9.4.25 (from tensorflow[and-cuda]->-r cdd/requirements.txt (line 47))\n",
            "  Using cached nvidia_cudnn_cu12-8.9.4.25-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.8.103 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]->-r cdd/requirements.txt (line 47)) (11.0.8.103)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.3.141 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]->-r cdd/requirements.txt (line 47)) (10.3.3.141)\n",
            "Collecting nvidia-cusolver-cu12==11.5.2.141 (from tensorflow[and-cuda]->-r cdd/requirements.txt (line 47))\n",
            "  Using cached nvidia_cusolver_cu12-11.5.2.141-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.2.141 (from tensorflow[and-cuda]->-r cdd/requirements.txt (line 47))\n",
            "  Using cached nvidia_cusparse_cu12-12.1.2.141-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.16.5 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]->-r cdd/requirements.txt (line 47)) (2.16.5)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchvision (from -r cdd/requirements.txt (line 36))\n",
            "  Using cached torchvision-0.20.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "  Using cached torchvision-0.20.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "  Using cached torchvision-0.19.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
            "  Using cached torchvision-0.19.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
            "  Using cached torchvision-0.18.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "  Using cached torchvision-0.18.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "INFO: pip is still looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "  Using cached torchvision-0.17.2-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "  Using cached torchvision-0.17.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "  Using cached torchvision-0.17.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "  Using cached torchvision-0.16.2-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "  Using cached torchvision-0.16.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Using cached torchvision-0.16.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "  Using cached torchvision-0.15.2-cp311-cp311-manylinux1_x86_64.whl.metadata (11 kB)\n",
            "INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchaudio (from -r cdd/requirements.txt (line 37))\n",
            "  Using cached torchaudio-2.5.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
            "  Using cached torchaudio-2.5.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
            "  Using cached torchaudio-2.4.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
            "  Using cached torchaudio-2.4.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
            "  Using cached torchaudio-2.3.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
            "  Using cached torchaudio-2.3.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
            "INFO: pip is still looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
            "  Using cached torchaudio-2.2.2-cp311-cp311-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
            "  Using cached torchaudio-2.2.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
            "  Using cached torchaudio-2.2.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
            "  Using cached torchaudio-2.1.2-cp311-cp311-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
            "  Using cached torchaudio-2.1.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Using cached torchaudio-2.1.0-cp311-cp311-manylinux1_x86_64.whl.metadata (5.7 kB)\n",
            "  Using cached torchaudio-2.0.2-cp311-cp311-manylinux1_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting tensorrt-cu12==10.9.0.34 (from tensorrt->-r cdd/requirements.txt (line 48))\n",
            "  Using cached tensorrt_cu12-10.9.0.34-py2.py3-none-any.whl\n",
            "Collecting tensorrt-cu12-libs==10.9.0.34 (from tensorrt-cu12==10.9.0.34->tensorrt->-r cdd/requirements.txt (line 48))\n",
            "  Using cached tensorrt_cu12_libs-10.9.0.34-py2.py3-none-manylinux_2_28_x86_64.whl\n",
            "Requirement already satisfied: tensorrt-cu12-bindings==10.9.0.34 in /usr/local/lib/python3.11/dist-packages (from tensorrt-cu12==10.9.0.34->tensorrt->-r cdd/requirements.txt (line 48)) (10.9.0.34)\n",
            "Collecting hypothesis>=6.92.7 (from pandera[strategies]>=0.15.0->-r cdd/requirements.txt (line 15))\n",
            "  Using cached hypothesis-6.129.3-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.0->locust<3,>=2.12.2->-r cdd/requirements.txt (line 10)) (2.2.0)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.0->locust<3,>=2.12.2->-r cdd/requirements.txt (line 10)) (1.9.0)\n",
            "Requirement already satisfied: zope.event in /usr/local/lib/python3.11/dist-packages (from gevent>=22.10.2->locust<3,>=2.12.2->-r cdd/requirements.txt (line 10)) (5.0)\n",
            "Requirement already satisfied: zope.interface in /usr/local/lib/python3.11/dist-packages (from gevent>=22.10.2->locust<3,>=2.12.2->-r cdd/requirements.txt (line 10)) (7.2)\n",
            "Requirement already satisfied: greenlet>=3.1.1 in /usr/local/lib/python3.11/dist-packages (from gevent>=22.10.2->locust<3,>=2.12.2->-r cdd/requirements.txt (line 10)) (3.1.1)\n",
            "Requirement already satisfied: brotli in /usr/local/lib/python3.11/dist-packages (from geventhttpclient>=2.3.1->locust<3,>=2.12.2->-r cdd/requirements.txt (line 10)) (1.1.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from hypothesis>=6.92.7->pandera[strategies]>=0.15.0->-r cdd/requirements.txt (line 15)) (25.2.0)\n",
            "Requirement already satisfied: sortedcontainers<3.0.0,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from hypothesis>=6.92.7->pandera[strategies]>=0.15.0->-r cdd/requirements.txt (line 15)) (2.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0.1->-r cdd/requirements.txt (line 35)) (3.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->fastai==2.7.19->-r cdd/requirements.txt (line 30)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->fastai==2.7.19->-r cdd/requirements.txt (line 30)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->fastai==2.7.19->-r cdd/requirements.txt (line 30)) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->fastai==2.7.19->-r cdd/requirements.txt (line 30)) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->fastai==2.7.19->-r cdd/requirements.txt (line 30)) (3.2.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (6.4.2)\n",
            "INFO: pip is looking at multiple versions of notebook to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting notebook<8,>=6.5.5 (from recommenders[gpu]->-r cdd/requirements.txt (line 44))\n",
            "  Using cached notebook-7.3.3-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting jupyter-server<3,>=2.4.0 (from notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44))\n",
            "  Using cached jupyter_server-2.15.0-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting jupyterlab-server<3,>=2.27.1 (from notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44))\n",
            "  Using cached jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting jupyterlab<4.4,>=4.3.6 (from notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44))\n",
            "  Using cached jupyterlab-4.3.6-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: notebook-shim<0.3,>=0.2 in /usr/local/lib/python3.11/dist-packages (from notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (0.2.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai==2.7.19->-r cdd/requirements.txt (line 30)) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai==2.7.19->-r cdd/requirements.txt (line 30)) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai==2.7.19->-r cdd/requirements.txt (line 30)) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai==2.7.19->-r cdd/requirements.txt (line 30)) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai==2.7.19->-r cdd/requirements.txt (line 30)) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai==2.7.19->-r cdd/requirements.txt (line 30)) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai==2.7.19->-r cdd/requirements.txt (line 30)) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai==2.7.19->-r cdd/requirements.txt (line 30)) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai==2.7.19->-r cdd/requirements.txt (line 30)) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai==2.7.19->-r cdd/requirements.txt (line 30)) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai==2.7.19->-r cdd/requirements.txt (line 30)) (0.15.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai==2.7.19->-r cdd/requirements.txt (line 30)) (3.5.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->pandera>=0.15.0->pandera[strategies]>=0.15.0->-r cdd/requirements.txt (line 15)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->pandera>=0.15.0->pandera[strategies]>=0.15.0->-r cdd/requirements.txt (line 15)) (2.27.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow!=2.10.0.*,!=2.9.0.*,!=2.9.1,!=2.9.2,<2.16,>=2.8.4->-r cdd/requirements.txt (line 33)) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow!=2.10.0.*,!=2.9.0.*,!=2.9.1,!=2.9.2,<2.16,>=2.8.4->-r cdd/requirements.txt (line 33)) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow!=2.10.0.*,!=2.9.0.*,!=2.9.1,!=2.9.2,<2.16,>=2.8.4->-r cdd/requirements.txt (line 33)) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow!=2.10.0.*,!=2.9.0.*,!=2.9.1,!=2.9.2,<2.16,>=2.8.4->-r cdd/requirements.txt (line 33)) (0.7.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing_inspect>=0.6.0->pandera>=0.15.0->pandera[strategies]>=0.15.0->-r cdd/requirements.txt (line 15))\n",
            "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow!=2.10.0.*,!=2.9.0.*,!=2.9.1,!=2.9.2,<2.16,>=2.8.4->-r cdd/requirements.txt (line 33)) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow!=2.10.0.*,!=2.9.0.*,!=2.9.1,!=2.9.2,<2.16,>=2.8.4->-r cdd/requirements.txt (line 33)) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow!=2.10.0.*,!=2.9.0.*,!=2.9.1,!=2.9.2,<2.16,>=2.8.4->-r cdd/requirements.txt (line 33)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow!=2.10.0.*,!=2.9.0.*,!=2.9.1,!=2.9.2,<2.16,>=2.8.4->-r cdd/requirements.txt (line 33)) (2.0.0)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (3.7.1)\n",
            "Requirement already satisfied: argon2-cffi>=21.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (23.1.0)\n",
            "Collecting jupyter-client>=7.4.4 (from jupyter-server<3,>=2.4.0->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44))\n",
            "  Using cached jupyter_client-8.6.3-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (5.7.2)\n",
            "Collecting jupyter-events>=0.11.0 (from jupyter-server<3,>=2.4.0->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44))\n",
            "  Using cached jupyter_events-0.12.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.4.0->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44))\n",
            "  Using cached jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: nbconvert>=6.4.4 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (7.16.6)\n",
            "Requirement already satisfied: nbformat>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (5.10.4)\n",
            "Requirement already satisfied: overrides>=5.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (7.7.0)\n",
            "Requirement already satisfied: prometheus-client>=0.9 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (0.21.1)\n",
            "Requirement already satisfied: send2trash>=1.8.2 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (0.18.1)\n",
            "Requirement already satisfied: traitlets>=5.6.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (5.7.1)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (1.8.0)\n",
            "Collecting async-lru>=1.0.0 (from jupyterlab<4.4,>=4.3.6->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44))\n",
            "  Using cached async_lru-2.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: httpx>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab<4.4,>=4.3.6->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (0.28.1)\n",
            "Requirement already satisfied: ipykernel>=6.5.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab<4.4,>=4.3.6->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (6.17.1)\n",
            "Collecting jupyter-lsp>=2.0.0 (from jupyterlab<4.4,>=4.3.6->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44))\n",
            "  Using cached jupyter_lsp-2.2.5-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (2.17.0)\n",
            "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.27.1->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44))\n",
            "  Using cached json5-0.10.0-py3-none-any.whl.metadata (34 kB)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (4.23.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<4->fastai==2.7.19->-r cdd/requirements.txt (line 30)) (1.3.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4->fastai==2.7.19->-r cdd/requirements.txt (line 30)) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4->fastai==2.7.19->-r cdd/requirements.txt (line 30)) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai==2.7.19->-r cdd/requirements.txt (line 30)) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai==2.7.19->-r cdd/requirements.txt (line 30)) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<4->fastai==2.7.19->-r cdd/requirements.txt (line 30)) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<4->fastai==2.7.19->-r cdd/requirements.txt (line 30)) (7.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (1.3.1)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (21.2.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab<4.4,>=4.3.6->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab<4.4,>=4.3.6->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (0.14.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab<4.4,>=4.3.6->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (1.8.0)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab<4.4,>=4.3.6->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (7.34.0)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab<4.4,>=4.3.6->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab<4.4,>=4.3.6->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (1.6.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (0.23.1)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server<3,>=2.4.0->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (4.3.6)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (3.3.0)\n",
            "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (0.1.4)\n",
            "Requirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (0.1.1)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4->fastai==2.7.19->-r cdd/requirements.txt (line 30)) (1.2.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (4.13.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (3.1.2)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (1.5.1)\n",
            "Requirement already satisfied: pygments>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (2.18.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (2.21.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow!=2.10.0.*,!=2.9.0.*,!=2.9.1,!=2.9.2,<2.16,>=2.8.4->-r cdd/requirements.txt (line 33)) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow!=2.10.0.*,!=2.9.0.*,!=2.9.1,!=2.9.2,<2.16,>=2.8.4->-r cdd/requirements.txt (line 33)) (3.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4->fastai==2.7.19->-r cdd/requirements.txt (line 30)) (3.0.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.11/dist-packages (from terminado>=0.8.3->jupyter-server<3,>=2.4.0->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (0.7.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (1.4.0)\n",
            "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab<4.4,>=4.3.6->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44))\n",
            "  Using cached jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab<4.4,>=4.3.6->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab<4.4,>=4.3.6->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab<4.4,>=4.3.6->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (3.0.50)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab<4.4,>=4.3.6->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab<4.4,>=4.3.6->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (4.9.0)\n",
            "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44))\n",
            "  Using cached fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44))\n",
            "  Using cached isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (3.0.0)\n",
            "Requirement already satisfied: uri-template in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (1.3.0)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (24.11.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4->fastai==2.7.19->-r cdd/requirements.txt (line 30)) (0.1.2)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (2.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (2.22)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab<4.4,>=4.3.6->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (0.8.4)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab<4.4,>=4.3.6->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (0.2.13)\n",
            "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44))\n",
            "  Using cached arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.11/dist-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook<8,>=6.5.5->recommenders[gpu]->-r cdd/requirements.txt (line 44)) (2.9.0.20241206)\n",
            "Using cached category_encoders-2.8.1-py3-none-any.whl (85 kB)\n",
            "Using cached cornac-2.3.0-cp311-cp311-manylinux1_x86_64.whl (25.4 MB)\n",
            "Using cached locust-2.33.2-py3-none-any.whl (2.3 MB)\n",
            "Using cached memory_profiler-0.61.0-py3-none-any.whl (31 kB)\n",
            "Using cached pandera-0.23.1-py3-none-any.whl (264 kB)\n",
            "Using cached dynaconf-3.2.10-py2.py3-none-any.whl (236 kB)\n",
            "Using cached tensorflow-2.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.3 MB)\n",
            "Using cached torch-2.0.1-cp311-cp311-manylinux1_x86_64.whl (619.9 MB)\n",
            "Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "Using cached nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "Using cached triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.4.25-py3-none-manylinux1_x86_64.whl (720.1 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.5.2.141-py3-none-manylinux1_x86_64.whl (124.9 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.2.141-py3-none-manylinux1_x86_64.whl (195.3 MB)\n",
            "Using cached keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "Using cached ml_dtypes-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "Using cached torchvision-0.15.2-cp311-cp311-manylinux1_x86_64.whl (6.0 MB)\n",
            "Using cached torchaudio-2.0.2-cp311-cp311-manylinux1_x86_64.whl (4.4 MB)\n",
            "Using cached ConfigArgParse-1.7-py3-none-any.whl (25 kB)\n",
            "Using cached flask_cors-5.0.1-py3-none-any.whl (11 kB)\n",
            "Using cached Flask_Login-0.6.3-py3-none-any.whl (17 kB)\n",
            "Using cached gevent-24.11.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.8 MB)\n",
            "Using cached geventhttpclient-2.3.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (112 kB)\n",
            "Using cached hypothesis-6.129.3-py3-none-any.whl (487 kB)\n",
            "Using cached notebook-7.3.3-py3-none-any.whl (13.1 MB)\n",
            "Using cached tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
            "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Using cached powerlaw-1.5-py3-none-any.whl (24 kB)\n",
            "Using cached recommenders-1.2.1-py3-none-any.whl (355 kB)\n",
            "Using cached jupyter_server-2.15.0-py3-none-any.whl (385 kB)\n",
            "Using cached jupyterlab-4.3.6-py3-none-any.whl (11.7 MB)\n",
            "Using cached jupyterlab_server-2.27.3-py3-none-any.whl (59 kB)\n",
            "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Using cached async_lru-2.0.5-py3-none-any.whl (6.1 kB)\n",
            "Using cached json5-0.10.0-py3-none-any.whl (34 kB)\n",
            "Using cached jupyter_client-8.6.3-py3-none-any.whl (106 kB)\n",
            "Using cached jupyter_events-0.12.0-py3-none-any.whl (19 kB)\n",
            "Using cached jupyter_lsp-2.2.5-py3-none-any.whl (69 kB)\n",
            "Using cached jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
            "Using cached jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "Using cached fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Using cached isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
            "Using cached arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "Installing collected packages: tensorrt-cu12-libs, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cublas-cu11, mypy-extensions, ml-dtypes, memory-profiler, keras, json5, jedi, hypothesis, fqdn, dynaconf, configargparse, async-lru, typing_inspect, tensorrt-cu12, scikit-surprise, nvidia-cusolver-cu12, nvidia-cusolver-cu11, nvidia-cudnn-cu11, jupyter-server-terminals, jupyter-client, gevent, arrow, tensorrt, powerlaw, pandera, isoduration, geventhttpclient, flask-login, flask-cors, tensorboard, locust, cornac, category-encoders, tensorflow, jupyter-events, jupyter-server, jupyterlab-server, jupyter-lsp, jupyterlab, notebook, recommenders, triton, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.1\n",
            "    Uninstalling ml-dtypes-0.4.1:\n",
            "      Successfully uninstalled ml-dtypes-0.4.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.8.0\n",
            "    Uninstalling keras-3.8.0:\n",
            "      Successfully uninstalled keras-3.8.0\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: jupyter-client\n",
            "    Found existing installation: jupyter-client 6.1.12\n",
            "    Uninstalling jupyter-client-6.1.12:\n",
            "      Successfully uninstalled jupyter-client-6.1.12\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.18.0\n",
            "    Uninstalling tensorboard-2.18.0:\n",
            "      Successfully uninstalled tensorboard-2.18.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.18.0\n",
            "    Uninstalling tensorflow-2.18.0:\n",
            "      Successfully uninstalled tensorflow-2.18.0\n",
            "  Attempting uninstall: jupyter-server\n",
            "    Found existing installation: jupyter-server 1.24.0\n",
            "    Uninstalling jupyter-server-1.24.0:\n",
            "      Successfully uninstalled jupyter-server-1.24.0\n",
            "  Attempting uninstall: notebook\n",
            "    Found existing installation: notebook 6.5.5\n",
            "    Uninstalling notebook-6.5.5:\n",
            "      Successfully uninstalled notebook-6.5.5\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.6.0+cu124\n",
            "    Uninstalling torchaudio-2.6.0+cu124:\n",
            "      Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires notebook==6.5.5, but you have notebook 7.3.3 which is incompatible.\n",
            "jax 0.5.2 requires ml_dtypes>=0.4.0, but you have ml-dtypes 0.3.2 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.15.1 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.15.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed arrow-1.3.0 async-lru-2.0.5 category-encoders-2.8.1 configargparse-1.7 cornac-2.3.0 dynaconf-3.2.10 flask-cors-5.0.1 flask-login-0.6.3 fqdn-1.5.1 gevent-24.11.1 geventhttpclient-2.3.3 hypothesis-6.129.3 isoduration-20.11.0 jedi-0.19.2 json5-0.10.0 jupyter-client-8.6.3 jupyter-events-0.12.0 jupyter-lsp-2.2.5 jupyter-server-2.15.0 jupyter-server-terminals-0.5.3 jupyterlab-4.3.6 jupyterlab-server-2.27.3 keras-2.15.0 locust-2.33.2 memory-profiler-0.61.0 ml-dtypes-0.3.2 mypy-extensions-1.0.0 notebook-7.3.3 nvidia-cublas-cu11-11.10.3.66 nvidia-cudnn-cu11-8.5.0.96 nvidia-cudnn-cu12-8.9.4.25 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusolver-cu12-11.5.2.141 nvidia-cusparse-cu12-12.1.2.141 pandera-0.23.1 powerlaw-1.5 recommenders-1.2.1 scikit-surprise-1.1.4 tensorboard-2.15.2 tensorflow-2.15.1 tensorrt-10.9.0.34 tensorrt-cu12-10.9.0.34 tensorrt-cu12-libs-10.9.0.34 torch-2.0.1 torchaudio-2.0.2 torchvision-0.15.2 triton-2.0.0 typing_inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pkg_resources\n",
        "!pip install -e $repo_path"
      ],
      "metadata": {
        "id": "GAgHJ4f8VtHP",
        "outputId": "5bfededd-a90e-4fb7-a5c4-2733e873171b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "GAgHJ4f8VtHP",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-a1b09ae40a41>:1: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
            "  import pkg_resources\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/cdd\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: category-encoders<3,>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from cdd==0.1.0) (2.8.1)\n",
            "Requirement already satisfied: cornac<3,>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from cdd==0.1.0) (2.3.0)\n",
            "Requirement already satisfied: hyperopt<1,>=0.2.7 in /usr/local/lib/python3.11/dist-packages (from cdd==0.1.0) (0.2.7)\n",
            "Requirement already satisfied: lightgbm<5,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from cdd==0.1.0) (4.5.0)\n",
            "Requirement already satisfied: locust<3,>=2.12.2 in /usr/local/lib/python3.11/dist-packages (from cdd==0.1.0) (2.33.2)\n",
            "Requirement already satisfied: memory-profiler<1,>=0.61.0 in /usr/local/lib/python3.11/dist-packages (from cdd==0.1.0) (0.61.0)\n",
            "Requirement already satisfied: nltk<4,>=3.8.1 in /usr/local/lib/python3.11/dist-packages (from cdd==0.1.0) (3.9.1)\n",
            "Requirement already satisfied: numba<1,>=0.57.0 in /usr/local/lib/python3.11/dist-packages (from cdd==0.1.0) (0.60.0)\n",
            "Requirement already satisfied: pandas<3.0.0,>2.0.0 in /usr/local/lib/python3.11/dist-packages (from cdd==0.1.0) (2.2.2)\n",
            "Requirement already satisfied: pandera>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from pandera[strategies]>=0.15.0; python_version >= \"3.9\"->cdd==0.1.0) (0.23.1)\n",
            "Requirement already satisfied: retrying<2,>=1.3.4 in /usr/local/lib/python3.11/dist-packages (from cdd==0.1.0) (1.3.4)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from cdd==0.1.0) (1.6.1)\n",
            "Requirement already satisfied: scikit-surprise>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from cdd==0.1.0) (1.1.4)\n",
            "Requirement already satisfied: seaborn<1,>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from cdd==0.1.0) (0.13.2)\n",
            "Requirement already satisfied: statsmodels>=0.14.4 in /usr/local/lib/python3.11/dist-packages (from cdd==0.1.0) (0.14.4)\n",
            "Requirement already satisfied: transformers<5,>=4.27.0 in /usr/local/lib/python3.11/dist-packages (from cdd==0.1.0) (4.48.3)\n",
            "Requirement already satisfied: dynaconf in /usr/local/lib/python3.11/dist-packages (from cdd==0.1.0) (3.2.10)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from cdd==0.1.0) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from cdd==0.1.0) (2.32.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from cdd==0.1.0) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from category-encoders<3,>=2.6.0->cdd==0.1.0) (1.26.4)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from category-encoders<3,>=2.6.0->cdd==0.1.0) (1.0.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from category-encoders<3,>=2.6.0->cdd==0.1.0) (1.13.1)\n",
            "Requirement already satisfied: powerlaw in /usr/local/lib/python3.11/dist-packages (from cornac<3,>=2.3.0->cdd==0.1.0) (1.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from hyperopt<1,>=0.2.7->cdd==0.1.0) (1.17.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.11/dist-packages (from hyperopt<1,>=0.2.7->cdd==0.1.0) (3.4.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from hyperopt<1,>=0.2.7->cdd==0.1.0) (1.0.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from hyperopt<1,>=0.2.7->cdd==0.1.0) (3.1.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.11/dist-packages (from hyperopt<1,>=0.2.7->cdd==0.1.0) (0.10.9.7)\n",
            "Requirement already satisfied: configargparse>=1.5.5 in /usr/local/lib/python3.11/dist-packages (from locust<3,>=2.12.2->cdd==0.1.0) (1.7)\n",
            "Requirement already satisfied: flask-cors>=3.0.10 in /usr/local/lib/python3.11/dist-packages (from locust<3,>=2.12.2->cdd==0.1.0) (5.0.1)\n",
            "Requirement already satisfied: flask-login>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from locust<3,>=2.12.2->cdd==0.1.0) (0.6.3)\n",
            "Requirement already satisfied: flask>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from locust<3,>=2.12.2->cdd==0.1.0) (3.1.0)\n",
            "Requirement already satisfied: gevent>=22.10.2 in /usr/local/lib/python3.11/dist-packages (from locust<3,>=2.12.2->cdd==0.1.0) (24.11.1)\n",
            "Requirement already satisfied: geventhttpclient>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from locust<3,>=2.12.2->cdd==0.1.0) (2.3.3)\n",
            "Requirement already satisfied: msgpack>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from locust<3,>=2.12.2->cdd==0.1.0) (1.1.0)\n",
            "Requirement already satisfied: psutil>=5.9.1 in /usr/local/lib/python3.11/dist-packages (from locust<3,>=2.12.2->cdd==0.1.0) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=25.0.0 in /usr/local/lib/python3.11/dist-packages (from locust<3,>=2.12.2->cdd==0.1.0) (26.3.0)\n",
            "Requirement already satisfied: setuptools>=70.0.0 in /usr/local/lib/python3.11/dist-packages (from locust<3,>=2.12.2->cdd==0.1.0) (75.1.0)\n",
            "Requirement already satisfied: werkzeug>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from locust<3,>=2.12.2->cdd==0.1.0) (3.1.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk<4,>=3.8.1->cdd==0.1.0) (8.1.8)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk<4,>=3.8.1->cdd==0.1.0) (2024.11.6)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba<1,>=0.57.0->cdd==0.1.0) (0.43.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>2.0.0->cdd==0.1.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>2.0.0->cdd==0.1.0) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>2.0.0->cdd==0.1.0) (2025.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from pandera>=0.15.0->pandera[strategies]>=0.15.0; python_version >= \"3.9\"->cdd==0.1.0) (24.2)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from pandera>=0.15.0->pandera[strategies]>=0.15.0; python_version >= \"3.9\"->cdd==0.1.0) (2.10.6)\n",
            "Requirement already satisfied: typeguard in /usr/local/lib/python3.11/dist-packages (from pandera>=0.15.0->pandera[strategies]>=0.15.0; python_version >= \"3.9\"->cdd==0.1.0) (4.4.2)\n",
            "Requirement already satisfied: typing_inspect>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pandera>=0.15.0->pandera[strategies]>=0.15.0; python_version >= \"3.9\"->cdd==0.1.0) (0.9.0)\n",
            "Requirement already satisfied: hypothesis>=6.92.7 in /usr/local/lib/python3.11/dist-packages (from pandera[strategies]>=0.15.0; python_version >= \"3.9\"->cdd==0.1.0) (6.129.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->cdd==0.1.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->cdd==0.1.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->cdd==0.1.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->cdd==0.1.0) (2025.1.31)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2,>=1.2.0->cdd==0.1.0) (3.5.0)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.11/dist-packages (from seaborn<1,>=0.13.0->cdd==0.1.0) (3.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers<5,>=4.27.0->cdd==0.1.0) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers<5,>=4.27.0->cdd==0.1.0) (0.28.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5,>=4.27.0->cdd==0.1.0) (6.0.2)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5,>=4.27.0->cdd==0.1.0) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5,>=4.27.0->cdd==0.1.0) (0.5.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.0->locust<3,>=2.12.2->cdd==0.1.0) (3.1.6)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.0->locust<3,>=2.12.2->cdd==0.1.0) (2.2.0)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.0->locust<3,>=2.12.2->cdd==0.1.0) (1.9.0)\n",
            "Requirement already satisfied: zope.event in /usr/local/lib/python3.11/dist-packages (from gevent>=22.10.2->locust<3,>=2.12.2->cdd==0.1.0) (5.0)\n",
            "Requirement already satisfied: zope.interface in /usr/local/lib/python3.11/dist-packages (from gevent>=22.10.2->locust<3,>=2.12.2->cdd==0.1.0) (7.2)\n",
            "Requirement already satisfied: greenlet>=3.1.1 in /usr/local/lib/python3.11/dist-packages (from gevent>=22.10.2->locust<3,>=2.12.2->cdd==0.1.0) (3.1.1)\n",
            "Requirement already satisfied: brotli in /usr/local/lib/python3.11/dist-packages (from geventhttpclient>=2.3.1->locust<3,>=2.12.2->cdd==0.1.0) (1.1.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers<5,>=4.27.0->cdd==0.1.0) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers<5,>=4.27.0->cdd==0.1.0) (4.12.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from hypothesis>=6.92.7->pandera[strategies]>=0.15.0; python_version >= \"3.9\"->cdd==0.1.0) (25.2.0)\n",
            "Requirement already satisfied: sortedcontainers<3.0.0,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from hypothesis>=6.92.7->pandera[strategies]>=0.15.0; python_version >= \"3.9\"->cdd==0.1.0) (2.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn<1,>=0.13.0->cdd==0.1.0) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn<1,>=0.13.0->cdd==0.1.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn<1,>=0.13.0->cdd==0.1.0) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn<1,>=0.13.0->cdd==0.1.0) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn<1,>=0.13.0->cdd==0.1.0) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn<1,>=0.13.0->cdd==0.1.0) (3.2.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing_inspect>=0.6.0->pandera>=0.15.0->pandera[strategies]>=0.15.0; python_version >= \"3.9\"->cdd==0.1.0) (1.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=2.0.0->locust<3,>=2.12.2->cdd==0.1.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath in /usr/local/lib/python3.11/dist-packages (from powerlaw->cornac<3,>=2.3.0->cdd==0.1.0) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->pandera>=0.15.0->pandera[strategies]>=0.15.0; python_version >= \"3.9\"->cdd==0.1.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->pandera>=0.15.0->pandera[strategies]>=0.15.0; python_version >= \"3.9\"->cdd==0.1.0) (2.27.2)\n",
            "Installing collected packages: cdd\n",
            "  Running setup.py develop for cdd\n",
            "Successfully installed cdd-0.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# configurar as variáveis de ambiente\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-21-openjdk-amd64\"\n",
        "\n",
        "os.environ[\"SPARK_DRIVER_EXTRACLASSPATH\"] = \"/content/spark/lib-jars/*\"\n",
        "os.environ[\"SPARK_EXECUTOR_EXTRACLASSPATH\"] = \"/content/spark/lib-jars/*\"\n",
        "os.environ[\"SPARK_SERIALIZER\"] = \"org.apache.spark.serializer.KryoSerializer\"\n",
        "os.environ[\"ENV\"] = \"dev\"\n",
        "os.environ[\"PYTHONUNBUFFERED\"] = \"1\"\n",
        "os.environ[\"SPARK_EXECUTOR_MEMORY\"] = \"8g\"\n",
        "os.environ[\"SPARK_DRIVER_MEMORY\"] = \"8g\"\n",
        "os.environ[\"SPARK_MEMORY_FRACTION\"] = \"0.8\"\n",
        "\n",
        "\n",
        "os.environ[\"DOWNLOAD_FOLDER\"] = \"/content/datasets\""
      ],
      "metadata": {
        "id": "H939YnnX-A3D"
      },
      "id": "H939YnnX-A3D",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "V4DTuR9P--H2"
      },
      "id": "V4DTuR9P--H2",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:  # When on Google Colab, clone the repository to download any necessary cache.\n",
        "    import google.colab\n",
        "    repo_path = 'cdd'\n",
        "    !git -C $repo_path pull origin || git clone https://github.com/hygo2025/cdd-projeto-final.git $repo_path\n",
        "except:\n",
        "    repo_path = '.'  # Use the local path if not on Google Colab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4xGPDpcYBHmU",
        "outputId": "4dbce931-e368-41f7-bb5e-94cfd9ab6fb8"
      },
      "id": "4xGPDpcYBHmU",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "import pkg_resources\n",
        "\n",
        "if repo_path not in sys.path:\n",
        "    sys.path.append(repo_path)"
      ],
      "metadata": {
        "id": "xPE1A11QBnM9"
      },
      "id": "xPE1A11QBnM9",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cdd"
      ],
      "metadata": {
        "id": "n6dYXTkxFlEF"
      },
      "id": "n6dYXTkxFlEF",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "full_results = pd.DataFrame()"
      ],
      "metadata": {
        "id": "oib-FQl_cw0W"
      },
      "id": "oib-FQl_cw0W",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from src.sar_model import SarModel\n",
        "from src.utils.enums import MovieLensDataset, SimilarityType\n",
        "\n",
        "def evaluate_sar():\n",
        "    top_k = 10\n",
        "    validate_size = 0.25\n",
        "    time_decay_coefficient = 30\n",
        "    seed = 42\n",
        "\n",
        "    df_results = pd.DataFrame()\n",
        "\n",
        "    # Chave para identificar a configuração: neste exemplo, utilizamos \"algorithm\" e \"similarity\"\n",
        "    key_columns = ['algorithm', 'similarity']\n",
        "\n",
        "    # Iterando sobre todas as similaridades definidas na enumeração\n",
        "    for similarity in SimilarityType:\n",
        "        print(f\"\\nTestando similaridade: {similarity.value}\")\n",
        "\n",
        "        # Instanciando o modelo com a similaridade atual\n",
        "        sar_model = SarModel(\n",
        "            dataset=MovieLensDataset.ML_1M,\n",
        "            top_k=top_k,\n",
        "            validate_size=validate_size,\n",
        "            time_decay_coefficient=time_decay_coefficient,\n",
        "            similarity_type=similarity,\n",
        "            seed=seed\n",
        "        )\n",
        "\n",
        "        # Avaliando o modelo\n",
        "        result = sar_model.evaluate()\n",
        "\n",
        "        result['version'] = f\"similarity_{similarity.value}_top_k_{top_k}_validate_size_{validate_size}_time_decay_coefficient_{time_decay_coefficient}\"\n",
        "        result['algorithm'] = 'sar'\n",
        "\n",
        "        df_results = pd.concat([df_results, result], ignore_index=True)\n",
        "\n",
        "        print(f\"Resultado para similaridade {similarity.value}:\")\n",
        "        print(result)\n",
        "    return df_results\n"
      ],
      "metadata": {
        "id": "H1K9GdD8QYrk"
      },
      "id": "H1K9GdD8QYrk",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sar_results = evaluate_sar()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "211XIAhvV6jM",
        "outputId": "df27a03f-f08a-4f09-d08e-8926d7b395f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "211XIAhvV6jM",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testando similaridade: cooccurrence\n",
            "Inicializando SarModel...\n",
            "Carregando e preparando os dados...\n",
            "/content/datasets\n",
            "ML_1M\n",
            "Dataset ML_1M não encontrado em /content/datasets/ML_1M. Iniciando download e extração...\n",
            "Iniciando download de: https://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
            "Progresso: 100.00%\n",
            "Download concluído.\n",
            "Descompactando /content/datasets/ml-1m.zip para /content/datasets/ML_1M...\n",
            "Descompactação concluída.\n",
            "/content/datasets\n",
            "ML_1M\n",
            "Dados carregados: 1000209 linhas.\n",
            "Dividindo os dados em treino e teste com python_stratified_split...\n",
            "Conjunto de treino: 750121 linhas, Conjunto de teste: 250088 linhas.\n",
            "Iniciando o processo de avaliação do modelo SAR...\n",
            "Iniciando o processo de predição com o modelo SAR...\n",
            "Iniciando treinamento do modelo SAR...\n",
            "Treinamento concluído. Salvando o modelo...\n",
            "Modelo salvo em: ../data/sar/movielens_sar_model_time_decay_coefficient_30_similarity_type_SimilarityType.COCCURRENCE_top_k_10.model\n",
            "Modelo SAR treinado e salvo com sucesso.\n",
            "Gerando recomendações (removendo itens já vistos)...\n",
            "Juntando títulos dos itens às recomendações...\n",
            "Processo de predição concluído.\n",
            "Calculando métricas de avaliação (ranking)...\n",
            "Avaliação concluída.\n",
            "Resultado para similaridade cooccurrence:\n",
            "        MAP    nDCG@K  Precision@K  Recall@K  \\\n",
            "0  0.173259  0.281954     0.252086  0.082533   \n",
            "\n",
            "                                             version algorithm  \n",
            "0  similarity_cooccurrence_top_k_10_validate_size...       sar  \n",
            "\n",
            "Testando similaridade: cosine\n",
            "Inicializando SarModel...\n",
            "Carregando e preparando os dados...\n",
            "/content/datasets\n",
            "ML_1M\n",
            "/content/datasets\n",
            "ML_1M\n",
            "Dados carregados: 1000209 linhas.\n",
            "Dividindo os dados em treino e teste com python_stratified_split...\n",
            "Conjunto de treino: 750121 linhas, Conjunto de teste: 250088 linhas.\n",
            "Iniciando o processo de avaliação do modelo SAR...\n",
            "Iniciando o processo de predição com o modelo SAR...\n",
            "Iniciando treinamento do modelo SAR...\n",
            "Treinamento concluído. Salvando o modelo...\n",
            "Modelo salvo em: ../data/sar/movielens_sar_model_time_decay_coefficient_30_similarity_type_SimilarityType.COSINE_top_k_10.model\n",
            "Modelo SAR treinado e salvo com sucesso.\n",
            "Gerando recomendações (removendo itens já vistos)...\n",
            "Juntando títulos dos itens às recomendações...\n",
            "Processo de predição concluído.\n",
            "Calculando métricas de avaliação (ranking)...\n",
            "Avaliação concluída.\n",
            "Resultado para similaridade cosine:\n",
            "        MAP   nDCG@K  Precision@K  Recall@K  \\\n",
            "0  0.219533  0.34561     0.307864  0.114765   \n",
            "\n",
            "                                             version algorithm  \n",
            "0  similarity_cosine_top_k_10_validate_size_0.25_...       sar  \n",
            "\n",
            "Testando similaridade: inclusion index\n",
            "Inicializando SarModel...\n",
            "Carregando e preparando os dados...\n",
            "/content/datasets\n",
            "ML_1M\n",
            "/content/datasets\n",
            "ML_1M\n",
            "Dados carregados: 1000209 linhas.\n",
            "Dividindo os dados em treino e teste com python_stratified_split...\n",
            "Conjunto de treino: 750121 linhas, Conjunto de teste: 250088 linhas.\n",
            "Iniciando o processo de avaliação do modelo SAR...\n",
            "Iniciando o processo de predição com o modelo SAR...\n",
            "Iniciando treinamento do modelo SAR...\n",
            "Treinamento concluído. Salvando o modelo...\n",
            "Modelo salvo em: ../data/sar/movielens_sar_model_time_decay_coefficient_30_similarity_type_SimilarityType.INCLUSION_INDEX_top_k_10.model\n",
            "Modelo SAR treinado e salvo com sucesso.\n",
            "Gerando recomendações (removendo itens já vistos)...\n",
            "Juntando títulos dos itens às recomendações...\n",
            "Processo de predição concluído.\n",
            "Calculando métricas de avaliação (ranking)...\n",
            "Avaliação concluída.\n",
            "Resultado para similaridade inclusion index:\n",
            "       MAP    nDCG@K  Precision@K  Recall@K  \\\n",
            "0  0.00692  0.020386     0.025563  0.005893   \n",
            "\n",
            "                                             version algorithm  \n",
            "0  similarity_inclusion index_top_k_10_validate_s...       sar  \n",
            "\n",
            "Testando similaridade: jaccard\n",
            "Inicializando SarModel...\n",
            "Carregando e preparando os dados...\n",
            "/content/datasets\n",
            "ML_1M\n",
            "/content/datasets\n",
            "ML_1M\n",
            "Dados carregados: 1000209 linhas.\n",
            "Dividindo os dados em treino e teste com python_stratified_split...\n",
            "Conjunto de treino: 750121 linhas, Conjunto de teste: 250088 linhas.\n",
            "Iniciando o processo de avaliação do modelo SAR...\n",
            "Iniciando o processo de predição com o modelo SAR...\n",
            "Iniciando treinamento do modelo SAR...\n",
            "Treinamento concluído. Salvando o modelo...\n",
            "Modelo salvo em: ../data/sar/movielens_sar_model_time_decay_coefficient_30_similarity_type_SimilarityType.JACCARD_top_k_10.model\n",
            "Modelo SAR treinado e salvo com sucesso.\n",
            "Gerando recomendações (removendo itens já vistos)...\n",
            "Juntando títulos dos itens às recomendações...\n",
            "Processo de predição concluído.\n",
            "Calculando métricas de avaliação (ranking)...\n",
            "Avaliação concluída.\n",
            "Resultado para similaridade jaccard:\n",
            "        MAP    nDCG@K  Precision@K  Recall@K  \\\n",
            "0  0.185099  0.309862     0.279222  0.109562   \n",
            "\n",
            "                                             version algorithm  \n",
            "0  similarity_jaccard_top_k_10_validate_size_0.25...       sar  \n",
            "\n",
            "Testando similaridade: lexicographers mutual information\n",
            "Inicializando SarModel...\n",
            "Carregando e preparando os dados...\n",
            "/content/datasets\n",
            "ML_1M\n",
            "/content/datasets\n",
            "ML_1M\n",
            "Dados carregados: 1000209 linhas.\n",
            "Dividindo os dados em treino e teste com python_stratified_split...\n",
            "Conjunto de treino: 750121 linhas, Conjunto de teste: 250088 linhas.\n",
            "Iniciando o processo de avaliação do modelo SAR...\n",
            "Iniciando o processo de predição com o modelo SAR...\n",
            "Iniciando treinamento do modelo SAR...\n",
            "Treinamento concluído. Salvando o modelo...\n",
            "Modelo salvo em: ../data/sar/movielens_sar_model_time_decay_coefficient_30_similarity_type_SimilarityType.LEXICOGRAPHERS_MUTUAL_INFORMATION_top_k_10.model\n",
            "Modelo SAR treinado e salvo com sucesso.\n",
            "Gerando recomendações (removendo itens já vistos)...\n",
            "Juntando títulos dos itens às recomendações...\n",
            "Processo de predição concluído.\n",
            "Calculando métricas de avaliação (ranking)...\n",
            "Avaliação concluída.\n",
            "Resultado para similaridade lexicographers mutual information:\n",
            "   MAP  nDCG@K  Precision@K  Recall@K  \\\n",
            "0  0.0     0.0          0.0       0.0   \n",
            "\n",
            "                                             version algorithm  \n",
            "0  similarity_lexicographers mutual information_t...       sar  \n",
            "\n",
            "Testando similaridade: lift\n",
            "Inicializando SarModel...\n",
            "Carregando e preparando os dados...\n",
            "/content/datasets\n",
            "ML_1M\n",
            "/content/datasets\n",
            "ML_1M\n",
            "Dados carregados: 1000209 linhas.\n",
            "Dividindo os dados em treino e teste com python_stratified_split...\n",
            "Conjunto de treino: 750121 linhas, Conjunto de teste: 250088 linhas.\n",
            "Iniciando o processo de avaliação do modelo SAR...\n",
            "Iniciando o processo de predição com o modelo SAR...\n",
            "Iniciando treinamento do modelo SAR...\n",
            "Treinamento concluído. Salvando o modelo...\n",
            "Modelo salvo em: ../data/sar/movielens_sar_model_time_decay_coefficient_30_similarity_type_SimilarityType.LIFT_top_k_10.model\n",
            "Modelo SAR treinado e salvo com sucesso.\n",
            "Gerando recomendações (removendo itens já vistos)...\n",
            "Juntando títulos dos itens às recomendações...\n",
            "Processo de predição concluído.\n",
            "Calculando métricas de avaliação (ranking)...\n",
            "Avaliação concluída.\n",
            "Resultado para similaridade lift:\n",
            "        MAP   nDCG@K  Precision@K  Recall@K  \\\n",
            "0  0.000098  0.00036     0.000414  0.000183   \n",
            "\n",
            "                                             version algorithm  \n",
            "0  similarity_lift_top_k_10_validate_size_0.25_ti...       sar  \n",
            "\n",
            "Testando similaridade: mutual information\n",
            "Inicializando SarModel...\n",
            "Carregando e preparando os dados...\n",
            "/content/datasets\n",
            "ML_1M\n",
            "/content/datasets\n",
            "ML_1M\n",
            "Dados carregados: 1000209 linhas.\n",
            "Dividindo os dados em treino e teste com python_stratified_split...\n",
            "Conjunto de treino: 750121 linhas, Conjunto de teste: 250088 linhas.\n",
            "Iniciando o processo de avaliação do modelo SAR...\n",
            "Iniciando o processo de predição com o modelo SAR...\n",
            "Iniciando treinamento do modelo SAR...\n",
            "Treinamento concluído. Salvando o modelo...\n",
            "Modelo salvo em: ../data/sar/movielens_sar_model_time_decay_coefficient_30_similarity_type_SimilarityType.MUTUAL_INFORMATION_top_k_10.model\n",
            "Modelo SAR treinado e salvo com sucesso.\n",
            "Gerando recomendações (removendo itens já vistos)...\n",
            "Juntando títulos dos itens às recomendações...\n",
            "Processo de predição concluído.\n",
            "Calculando métricas de avaliação (ranking)...\n",
            "Avaliação concluída.\n",
            "Resultado para similaridade mutual information:\n",
            "       MAP   nDCG@K  Precision@K  Recall@K  \\\n",
            "0  0.00806  0.01879     0.019472  0.003072   \n",
            "\n",
            "                                             version algorithm  \n",
            "0  similarity_mutual information_top_k_10_validat...       sar  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_results = pd.concat([full_results, sar_results], ignore_index=True)"
      ],
      "metadata": {
        "id": "XthPbpk3c15N"
      },
      "id": "XthPbpk3c15N",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import pandas as pd\n",
        "from src.utils.enums import MovieLensDataset\n",
        "from src.als_model import SparkAlsModel\n",
        "\n",
        "def evaluate_als(spark):\n",
        "    # Definindo os grids de parâmetros\n",
        "    max_iter_options = [10, 20, 30]\n",
        "    rank_options = [10, 20, 30]\n",
        "    reg_param_options = [0.01, 0.05, 0.1]\n",
        "    alpha_options = [0.1, 0.5, 1.0]\n",
        "\n",
        "    # Parâmetros fixos\n",
        "    validate_size = 0.25\n",
        "    top_k = 10\n",
        "    seed = 42\n",
        "    dataset = MovieLensDataset.ML_1M\n",
        "\n",
        "    # Cria um DataFrame vazio para armazenar os resultados\n",
        "    df_results = pd.DataFrame()\n",
        "\n",
        "    # Itera por todas as combinações de parâmetros\n",
        "    for max_iter, rank, reg_param, alpha in itertools.product(\n",
        "            max_iter_options, rank_options, reg_param_options, alpha_options\n",
        "    ):\n",
        "        print(f\"\\nTestando: maxIter={max_iter}, rank={rank}, regParam={reg_param}, alpha={alpha}\")\n",
        "\n",
        "        # Instanciando o modelo ALS com a configuração atual\n",
        "        als_model = SparkAlsModel(\n",
        "            spark=spark,\n",
        "            dataset=dataset,\n",
        "            max_iter=max_iter,\n",
        "            rank=rank,\n",
        "            reg_param=reg_param,\n",
        "            alpha=alpha,\n",
        "            validate_size=validate_size,\n",
        "            top_k=top_k,\n",
        "            seed=seed\n",
        "        )\n",
        "\n",
        "\n",
        "        # Avaliando o modelo\n",
        "        result = als_model.evaluate()\n",
        "\n",
        "        # Adiciona as informações desejadas\n",
        "        result['algorithm'] = 'als'\n",
        "        result['version'] = f\"max_iter_{max_iter}_rank_{rank}_reg_param_{reg_param}_alpha_{alpha}\"\n",
        "\n",
        "        df_results = pd.concat([df_results, result], ignore_index=True)\n",
        "        print(f\"Resultado: {result}\")\n",
        "\n",
        "\n",
        "    return df_results"
      ],
      "metadata": {
        "id": "BjUzjxEKZAKE"
      },
      "id": "BjUzjxEKZAKE",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from src.utils.spark_session_utils import create_spark_session\n",
        "\n",
        "spark = create_spark_session(\"ALS\")\n",
        "als_result = evaluate_als(spark)\n"
      ],
      "metadata": {
        "id": "HX3T0HZwcNDJ",
        "outputId": "a45c6cfa-a096-4761-cb84-6ce62e7e1014",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "HX3T0HZwcNDJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testando: maxIter=10, rank=10, regParam=0.01, alpha=0.1\n",
            "Inicializando SparkAlsModel...\n",
            "Carregando e preparando os dados com prepare_data_spark...\n",
            "/content/datasets\n",
            "ML_1M\n",
            "/content/datasets\n",
            "ML_1M\n",
            "Dados carregados: 1000209 linhas.\n",
            "Dividindo os dados em conjuntos de treino e teste...\n",
            "Conjunto de treino: 750185 linhas; Conjunto de teste: 250024 linhas.\n",
            "Filtrando o conjunto de teste para manter apenas usuários presentes no treino...\n",
            "Após filtragem, teste possui: 250024 linhas.\n",
            "\n",
            "Iniciando avaliação do modelo ALS...\n",
            "Gerando predições para avaliação...\n",
            "Iniciando predição com o modelo ALS...\n",
            "Iniciando treinamento do modelo ALS...\n",
            "Treinamento concluído. Salvando o modelo...\n",
            "Obtendo usuários e itens distintos do conjunto de treino...\n",
            "Realizando cross join entre usuários e itens...\n",
            "Gerando predições utilizando o modelo ALS...\n",
            "Removendo itens já vistos (presentes no treino)...\n",
            "Predição concluída.\n",
            "\n",
            "Calculando métricas de avaliação de ranking...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "full_results = pd.concat([full_results, als_result], ignore_index=True)"
      ],
      "metadata": {
        "id": "WOoltmN0dvEp"
      },
      "id": "WOoltmN0dvEp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_results"
      ],
      "metadata": {
        "id": "xVn8JhV1o30_"
      },
      "id": "xVn8JhV1o30_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import pandas as pd\n",
        "from src.utils.enums import MovieLensDataset\n",
        "from src.ncf_model import NcfModel\n",
        "\n",
        "def evaluate_ncf():\n",
        "    # Parâmetros a serem testados\n",
        "    n_factors_options = [42, 64]\n",
        "    batch_size_options = [256, 512]\n",
        "    lr_options = [1e-3, 1e-4]\n",
        "    epochs_options = [1, 5]\n",
        "\n",
        "    # Parâmetros fixos\n",
        "    layer_sizes = [16, 8, 4]\n",
        "    top_k = 10\n",
        "    test_size = 0.2\n",
        "    seed = 42\n",
        "    dataset = MovieLensDataset.ML_1M\n",
        "\n",
        "    # Cria um DataFrame vazio para armazenar os resultados\n",
        "    df_results = pd.DataFrame()\n",
        "\n",
        "    # Itera por todas as combinações de parâmetros\n",
        "    for n_factors, batch_size, lr, epochs in itertools.product(\n",
        "        n_factors_options, batch_size_options, lr_options, epochs_options\n",
        "    ):\n",
        "        print(f\"\\nTestando: n_factors={n_factors}, batch_size={batch_size}, lr={lr}, epochs={epochs}\")\n",
        "\n",
        "        # Instancia o modelo NCF com a configuração atual\n",
        "        model = NcfModel(\n",
        "            dataset=dataset,\n",
        "            n_factors=n_factors,\n",
        "            batch_size=batch_size,\n",
        "            lr=lr,\n",
        "            layer_sizes=layer_sizes,\n",
        "            epochs=epochs,\n",
        "            top_k=top_k,\n",
        "            test_size=test_size,\n",
        "            seed=seed\n",
        "        )\n",
        "\n",
        "        # Avalia o modelo\n",
        "        result = model.evaluate()\n",
        "\n",
        "        # Adiciona informações de identificação\n",
        "        result['algorithm'] = 'ncf'\n",
        "        result['version'] = f\"n_factors_{n_factors}_batch_size_{batch_size}_lr_{lr}_epochs_{epochs}\"\n",
        "\n",
        "        df_results = pd.concat([df_results, result], ignore_index=True)\n",
        "\n",
        "        print(f\"Resultado: {result}\")\n",
        "\n",
        "    return df_results"
      ],
      "metadata": {
        "id": "YxsLihPdpeCk"
      },
      "id": "YxsLihPdpeCk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import pandas as pd\n",
        "from src.utils.enums import MovieLensDataset\n",
        "from src.bivae_model import BivaeModel\n",
        "\n",
        "def evaluate_bivae():\n",
        "    # Parâmetros a serem testados\n",
        "    latent_dim_options = [50, 100]\n",
        "    epochs_options = [100, 200]\n",
        "    lr_options = [0.005, 0.01]\n",
        "\n",
        "    # Parâmetros fixos\n",
        "    top_k = 10\n",
        "    batch_size = 1024\n",
        "    encoder_dims = [100]       # Pode ser ajustado se necessário\n",
        "    act_func = 'tanh'\n",
        "    likelihood = 'pois'\n",
        "    test_size = 0.2\n",
        "    seed = 42\n",
        "    dataset = MovieLensDataset.ML_1M\n",
        "\n",
        "    # Cria um DataFrame vazio para armazenar os resultados\n",
        "    df_results = pd.DataFrame()\n",
        "\n",
        "    # Itera por todas as combinações de parâmetros\n",
        "    for latent_dim, epochs, lr in itertools.product(\n",
        "        latent_dim_options, epochs_options, lr_options\n",
        "    ):\n",
        "        print(f\"\\nTestando: latent_dim={latent_dim}, epochs={epochs}, lr={lr}\")\n",
        "\n",
        "        # Instancia o modelo BivaeModel com a configuração atual\n",
        "        model = BivaeModel(\n",
        "            dataset=dataset,\n",
        "            top_k=top_k,\n",
        "            batch_size=batch_size,\n",
        "            latent_dim=latent_dim,\n",
        "            encoder_dims=encoder_dims,\n",
        "            act_func=act_func,\n",
        "            likelihood=likelihood,\n",
        "            epochs=epochs,\n",
        "            lr=lr,\n",
        "            test_size=test_size,\n",
        "            seed=seed\n",
        "        )\n",
        "\n",
        "        # Avalia o modelo\n",
        "        result = model.evaluate()\n",
        "\n",
        "        # Adiciona informações de identificação\n",
        "        result['algorithm'] = 'bivae'\n",
        "        result['version'] = f\"latent_dim_{latent_dim}_epochs_{epochs}_lr_{lr}\"\n",
        "\n",
        "        # Converte o dicionário de resultado em um DataFrame de uma linha e concatena\n",
        "        df_results = pd.concat([df_results, pd.DataFrame([result])], ignore_index=True)\n",
        "\n",
        "        print(f\"Resultado: {result}\")\n",
        "\n",
        "    return df_results\n"
      ],
      "metadata": {
        "id": "VO6C4c6CqQzu"
      },
      "id": "VO6C4c6CqQzu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import pandas as pd\n",
        "from src.utils.enums import MovieLensDataset\n",
        "from src.light_gcn_model import LightGcnModel\n",
        "\n",
        "def evaluate_lightgcn():\n",
        "    # Parâmetros a serem testados\n",
        "    n_layers_options = [2, 3, 4]\n",
        "    lr_options = [0.005, 0.01]\n",
        "    epochs_options = [1, 5]\n",
        "\n",
        "    # Parâmetros fixos\n",
        "    batch_size = 1024\n",
        "    top_k = 10\n",
        "    test_size = 0.2\n",
        "    seed = 42\n",
        "    dataset = MovieLensDataset.ML_1M\n",
        "\n",
        "    # Cria um DataFrame vazio para armazenar os resultados\n",
        "    df_results = pd.DataFrame()\n",
        "\n",
        "    # Itera por todas as combinações de parâmetros\n",
        "    for n_layers, lr, epochs in itertools.product(n_layers_options, lr_options, epochs_options):\n",
        "        print(f\"\\nTestando: n_layers={n_layers}, lr={lr}, epochs={epochs}\")\n",
        "\n",
        "        # Instancia o modelo LightGcnModel com a configuração atual\n",
        "        model = LightGcnModel(\n",
        "            dataset=dataset,\n",
        "            n_layers=n_layers,\n",
        "            batch_size=batch_size,\n",
        "            lr=lr,\n",
        "            epochs=epochs,\n",
        "            top_k=top_k,\n",
        "            test_size=test_size,\n",
        "            seed=seed\n",
        "        )\n",
        "\n",
        "        # Avalia o modelo\n",
        "        result = model.evaluate()\n",
        "\n",
        "        # Adiciona informações de identificação\n",
        "        result['algorithm'] = 'lightgcn'\n",
        "        result['version'] = f\"n_layers_{n_layers}_lr_{lr}_epochs_{epochs}\"\n",
        "\n",
        "        # Converte o dicionário de resultado em um DataFrame de uma linha e concatena\n",
        "        df_results = pd.concat([df_results, pd.DataFrame([result])], ignore_index=True)\n",
        "\n",
        "        print(f\"Resultado: {result}\")\n",
        "\n",
        "    return df_results\n"
      ],
      "metadata": {
        "id": "Xih-qDW4qbEx"
      },
      "id": "Xih-qDW4qbEx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import pandas as pd\n",
        "from src.utils.enums import MovieLensDataset\n",
        "from src.fastai_model import FastAiModel\n",
        "\n",
        "def evaluate_fastai():\n",
        "    # Parâmetros a serem testados\n",
        "    n_factors_options = [40, 50]\n",
        "    epochs_options = [1, 2]\n",
        "\n",
        "    # Parâmetros fixos\n",
        "    test_size = 0.25\n",
        "    top_k = 10\n",
        "    seed = 42\n",
        "    dataset = MovieLensDataset.ML_1M\n",
        "\n",
        "    # Cria um DataFrame vazio para armazenar os resultados\n",
        "    df_results = pd.DataFrame()\n",
        "\n",
        "    # Itera por todas as combinações de parâmetros\n",
        "    for n_factors, epochs in itertools.product(n_factors_options, epochs_options):\n",
        "        print(f\"\\nTestando: n_factors={n_factors}, epochs={epochs}\")\n",
        "\n",
        "        # Instancia o modelo FastAiModel com a configuração atual\n",
        "        model = FastAiModel(\n",
        "            dataset=dataset,\n",
        "            n_factors=n_factors,\n",
        "            test_size=test_size,\n",
        "            epochs=epochs,\n",
        "            top_k=top_k,\n",
        "            seed=seed\n",
        "        )\n",
        "\n",
        "        # Avalia o modelo\n",
        "        result = model.evaluate()\n",
        "\n",
        "        # Adiciona informações de identificação\n",
        "        result['algorithm'] = 'fastai'\n",
        "        result['version'] = f\"n_factors_{n_factors}_epochs_{epochs}\"\n",
        "\n",
        "        # Converte o dicionário de resultado em um DataFrame de uma linha e concatena\n",
        "        df_results = pd.concat([df_results, pd.DataFrame([result])], ignore_index=True)\n",
        "\n",
        "        print(f\"Resultado: {result}\")\n",
        "\n",
        "    return df_results\n"
      ],
      "metadata": {
        "id": "qmaQVlkUqeKn"
      },
      "id": "qmaQVlkUqeKn",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}